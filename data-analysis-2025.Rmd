---
title: "Data Analysis Notebook"
output: html_notebook
---

```{r}
#Authors: Ian McElveen and Cecilia Gonzales
#Author Date: 7/14/2025
#Purpose: The purpose of this notebook is to house all data set transformation, cleansing, visualization, statistical analysis, and note-taking for the 2025 CU Athletic Department Sports Science Internship Program

#LAST UPDATED: 7/29/2025

#Including helpful libraries
library(tidyverse)
library(readxl)
library(aod)
library(gt)
library(boot)
library(mgcv)
library(lme4)
library(leaps)
```


# Data Cleaning
```{r Loading in the data sets}
#loading in the Catapult data to look at sprinting values
Catapult_Session <- read_csv("data-sets/data-sets-uncompressed/data-sets-compressed/Running Imbalance and Speed/Catapult Session - Outdoor FB.csv")

#loading in the Historical Running data to look at running imbalance values
Historical_Running <- read_csv("data-sets/data-sets-uncompressed/data-sets-compressed/Running Imbalance and Speed/Compiled Historical Running Imbalance FB.csv")

#loading in the Incident Report to look at HSIs
Incident_Report <- read_csv("data-sets/data-sets-uncompressed/data-sets-compressed/Running Imbalance and Speed/Incident Report FB IDs.csv")

```

```{r Cleaning Catapult_Session}
Catapult_Session_clean <- Catapult_Session %>%
  #putting the date as a date class
  mutate(Date = as.Date(Date, "%m/%d/%Y")) %>%
  #only selecting important columns for this analysis
  select(anon_id, Date, Age, Primary.Position, Total.Distance, Period.Name, Total.Duration..min., Velocity.Band.1.Total.Distance, Velocity.Band.2.Total.Distance, Velocity.Band.3.Total.Distance, Velocity.Band.4.Total.Distance, Velocity.Band.5.Total.Distance, Velocity.Band.6.Total.Distance, Velocity.Band.7.Total.Distance, Velocity.Band.8.Total.Distance, Velocity.Band.2.Total.Effort.Count, Velocity.Band.3.Total.Effort.Count, Velocity.Band.4.Total.Effort.Count, Velocity.Band.5.Total.Effort.Count, Velocity.Band.6.Total.Effort.Count, Velocity.Band.7.Total.Effort.Count, Velocity.Band.8.Total.Effort.Count, Maximum.Velocity, Average.Velocity, Hit.90.Percent.Max, Date.of.Last.90.Effort, Days.Since.Last.90.Effort, Hit.Max.Velocity., Date.of.All.Time.Max.Velocity, Days.Since.Max.Velocity, Session.Max.Velocity) %>%
  #calculating each player's maximum velocity
  group_by(anon_id) %>%
  mutate(Player.Max.Velocity = max(na.omit(Maximum.Velocity))) %>%
  ungroup() %>%
  #only selecting data from January 1, 2024 and on
  filter(Date >= "2024-01-01")

head(Catapult_Session_clean)
```

```{r Cleaning Historical_Running}
Historical_Running_clean <- Historical_Running %>%
  #taking out rows that don't have data
  filter(Running.Imbalance != "n/a") %>%
  #putting running imbalance as a number and converting the date to a date class
  mutate(Running.Imbalance = as.numeric(Running.Imbalance),
         Date = as.Date(Date, "%m/%d/%Y")) %>%
  #only using data from January 1, 2024 and on
  filter(Date >= "2024-01-01") %>%
  mutate(X=1:4063) %>%
  #making days since January 1, 2024 for each player
  group_by(anon_id) %>%
  mutate(Days.Since.Start = as.numeric(Date - min(Date))) %>%
  ungroup()

head(Historical_Running_clean)
```

```{r Cleaning Incident_Report}
Incident_Report_clean <- Incident_Report %>%
  #filtering for only hamstring injuries
  filter(OSICS14.Code == "TM1",
         Status != "Full Go")  %>%
  #getting the date of the injury as a date class
  mutate(Date = as.Date(Date, "%m/%d/%Y"),
         Date.of.Injury = as.Date(Date.of.Injury...Onset.of.symptoms, "%m/%d/%Y"),
         Examination.Date = as.Date(Examination.Date, "%m/%d/%Y")) %>%
  #only selecting relevant columns for this analysis
  select(anon_id, Position, Date, Date.of.Injury, Time.of.Injury, Side, OSICS.Injury.Diagnosis, Coach.s.Diagnosis, Recurrence.of.Injury, Choose.Season, Onset.of.Symptoms, Injury.Prognosis, General.Mechanism, Specific.Mechanism, Injured.While., Type.of.Event, Season., Status, Days.in.Status) %>%
  #making days out due to injury for each player and each injury they sustained
  group_by(anon_id, Date.of.Injury) %>%
  mutate(Days.Out = sum(Days.in.Status)) %>%
  ungroup()

head(Incident_Report_clean)
```

```{r Identifying players that have data in both data sets}
#taking the IDs of players who are and aren't injured
all_IDs <- unique(Historical_Running_clean$anon_id)
#taking IDs that were injured and also have running imbalance data
injured_IDs <- intersect(unique(Incident_Report_clean$anon_id), all_IDs)
#taking all players with running imbalance data that don't have an injury
uninjured_IDs <- unique((Historical_Running_clean %>%
  filter(!anon_id %in% injured_IDs))$anon_id)
```

```{r Filtering out players without proper data from all data sets}
#injured players who also have running imbalance data
Incident_Report_clean <- Incident_Report_clean %>%
  filter(anon_id %in% injured_IDs)

#all players that only have running imbalance data or have both running imbalance data and incidence report
Historical_Running_clean <- Historical_Running_clean %>%
  filter(anon_id %in% injured_IDs | anon_id %in% uninjured_IDs)
```

```{r Removing all unimportant objects created during cleaning}
#removing uncleaned data sets
remove(Incident_Report)
remove(Historical_Running)
remove(Catapult_Session)
```

# Section 1: Running Speed

## How often are athletes reaching ≥ 90% maximum velocity throughout a training season?

```{r}
# Bar chart for how often players reach ≥ 90% maximum velocity

# Count for how many times each anon_id hit ≥ 90% maximum velocity
hit_90_counts <- Catapult_Session_clean %>%
  filter(Date >= as.Date("2024-06-30") & Date <= as.Date("2025-07-01")) %>% # Filter for training season
  filter(Hit.90.Percent.Max == "Yes") %>%
  distinct(anon_id, Date, Primary.Position) %>%
  group_by(anon_id, Primary.Position) %>%
  summarise(times_hit_90 = n(), .groups = "drop") %>%
  mutate(
    Position_Group = case_when(
      Primary.Position %in% c("QB", "LB", "TE", "RB") ~ "COMBO",
      Primary.Position %in% c("OL", "DL", "DE") ~ "BIGS",
      Primary.Position %in% c("WR", "DB", "DB, WR") ~ "SKILL",
      TRUE ~ "OTHER"
    ))

# Plot of all players' frequencies
ggplot(hit_90_counts, aes(x = anon_id, y = times_hit_90)) +
  geom_bar(stat = "identity", fill = "#CFB87C") +
  geom_hline(yintercept = mean(hit_90_counts$times_hit_90), 
             linetype = "dashed", color = "#565A5C", linewidth = 0.5) +
  labs(title = "Player Counts for Achieving ≥ 90% of Maximum Velocity During 2024–25 Season", 
       subtitle = paste("Team Average:", round(mean(hit_90_counts$times_hit_90), 1)),
       x = "Athlete ID", y = "Times ≥ 90%") +
  theme_classic() +
  theme(axis.text.x = element_text(size = 6, angle = 90))
```
# Do not need because we created a function to plot each position
```{r}
# Bar chart of times reached >90%, Quarterbacks

# Filter to only have data for QBs
QBs <- hit_90_counts %>%
  filter(Primary.Position == "QB")

# Calculate the averages first
overall_avg <- mean(hit_90_counts$times_hit_90)
qb_avg <- mean(QBs$times_hit_90)

ggplot(QBs, aes(x=anon_id, y=times_hit_90)) +
  geom_bar(stat="identity", fill = "#CFB87C") + 
  geom_text(aes(label = times_hit_90), 
            vjust = -0.5, 
            size = 3.5) +
  geom_hline(yintercept = overall_avg, 
             linetype = "dashed", color = "#000000") +
  geom_hline(yintercept = qb_avg, 
             linetype = "dashed", color = "#565A5C") +
  annotate("text", x = 1, y = overall_avg + 0.5, 
           label = "Team Avg", color = "#000000", size = 3) +
  annotate("text", x = 1, y = qb_avg + 0.5, 
           label = "QB Avg", color = "#565A5C", size = 3) +
  labs(title = "QB Counts for Reaching ≥90% Max Velocity", 
       x = "Athlete ID", y = "Times ≥90%",
       subtitle = paste("QB Average:", qb_avg)) +
  theme_classic()

```

## Facet plot useful, but hard to read so probably don't include in presentation.
```{r}
# Facet Plot

# Calculate overall average
overall_avg <- mean(hit_90_counts$times_hit_90)

# Plot faceted bar charts by position
ggplot(hit_90_counts, aes(x = anon_id, y = times_hit_90)) +
  geom_bar(stat = "identity", fill = "#CFB87C") +
  geom_text(aes(label = times_hit_90), vjust = -0.5, size = 3.5) +
  geom_hline(yintercept = overall_avg, linetype = "dashed", color = "#000000") +
  annotate("text", x = 1, y = overall_avg + 0.5, 
           label = "Team Avg", color = "#000000", size = 3, hjust = 0) +
  facet_wrap(~ Primary.Position, scales = "free_x") +
  labs(title = "Counts of ≥90% Max Velocity by Player and Position",
       y = "Times ≥90% Max Velocity",
       x = "Athlete ID") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Plots for each position

# Get the overall team average once from hit_90_counts
team_avg <- mean(hit_90_counts$times_hit_90)

# Define  positions to loop through
positions <- unique(hit_90_counts$Primary.Position)

# Plotting function:
plot_hit_90_by_position <- function(pos) {
  position_data <- hit_90_counts %>%
    filter(Primary.Position == pos)
  
  pos_avg <- mean(position_data$times_hit_90)
  
  ggplot(position_data, aes(x = anon_id, y = times_hit_90)) +
    geom_bar(stat = "identity", fill = "#CFB87C") +
    geom_text(aes(label = times_hit_90), vjust = -0.5, size = 3.5) +
    geom_hline(yintercept = pos_avg, linetype = "dashed", color = "#565A5C") +
    annotate("text", x = 1, y = pos_avg + 0.5, 
             label = "Pos Avg", color = "#565A5C", size = 3, hjust = 0) +
    geom_hline(yintercept = team_avg, linetype = "dashed", color = "#000000") +
    annotate("text", x = 1, y = team_avg + 0.5, 
             label = "Team Avg", color = "#000000", size = 3, hjust = 0) +
    labs(title = paste("Times ≥90% Max Velocity –", pos),
         subtitle = paste0("Position Avg: ", round(pos_avg, 1),
                           " | Team Avg: ", round(team_avg, 1)),
         y = "Count",
         x = "anon_id") +
    theme_classic() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

# Loop through each position and print the plot
plots_by_position <- lapply(positions, function(pos) {
  print(plot_hit_90_by_position(pos))
})

```

```{r}
# Table for average values of each position

position_averages <- hit_90_counts %>%
  group_by(Primary.Position) %>%
  summarise(avg_times_hit_90 = mean(times_hit_90), .groups = "drop") %>%
  arrange(desc(avg_times_hit_90))

position_averages_with_team <- bind_rows(
  tibble(
    Primary.Position = "Team Average",
    avg_times_hit_90 = team_avg
  ),
  position_averages
)

position_averages_with_team %>%
  gt() %>%
  tab_header(
    title = "Average Times ≥90% Max Velocity by Position and Team"
  )
```

DBs have the highest average times reaching ≥90% of Max velocity (18.4). The OL had the lowest (6.8). Team average was 11.8.

```{r}
# Plot counts for each position group

# Get the overall team average once from hit_90_counts
team_avg <- mean(hit_90_counts$times_hit_90)

# Define  positions to loop through
positions_groups <- unique(hit_90_counts$Position_Group)

# Plotting function:
plot_hit_90_group <- function(pos) {
  group_data <- hit_90_counts %>%
    filter(Position_Group == pos)
  
  group_avg <- mean(group_data$times_hit_90)
  
  ggplot(group_data, aes(x = anon_id, y = times_hit_90)) +
    geom_bar(stat = "identity", fill = "#CFB87C") +
    geom_text(aes(label = times_hit_90), vjust = -0.5, size = 3.5) +
    geom_hline(yintercept = group_avg, linetype = "dashed", color = "#565A5C") +
    annotate("text", x = 1, y = group_avg + 0.5, 
             label = "Group Avg", color = "#565A5C", size = 3, hjust = 0) +
    geom_hline(yintercept = team_avg, linetype = "dashed", color = "#000000") +
    annotate("text", x = 1, y = team_avg + 0.5, 
             label = "Team Avg", color = "#000000", size = 3, hjust = 0) +
    labs(title = paste("Times ≥90% Max Velocity –", pos),
         subtitle = paste0("Group Avg: ", round(group_avg, 1),
                           " | Team Avg: ", round(team_avg, 1)),
         y = "Count",
         x = "anon_id") +
    theme_classic() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

# Loop through each position and print the plot
plots_by_group <- lapply(positions_groups, function(pos) {
  print(plot_hit_90_group(pos))
})

```
The skill position group has the highest average times reached ≥90% Max with 17.1, then combo with 9.3, then bigs with 8.9.

```{r}
# Create position group avg count table

# Create team average row
team_row <- tibble(
  Group = "Team Avg",
  Average = team_avg
)

# Create group average rows
group_rows <- hit_90_counts %>%
  group_by(Position_Group) %>%
  summarise(Average = mean(times_hit_90), .groups = "drop") %>%
  arrange(desc(Average)) %>%  # Sort from highest to lowest
  rename(Group = Position_Group)

# Combine them (team first)
combined_table <- bind_rows(team_row, group_rows)

# View the table
combined_table
```
No surprise that the skill position group has the highest average counts. 

```{r}
# >90% counts over the course of the season

# Trying to find out when are players reaching above 90% the most

# Create dataset that has the count of >90% of each day
daily_90_counts <- Catapult_Session_clean %>%
  filter(Date >= as.Date("2024-06-30") & Date <= as.Date("2025-07-01")) %>%
  filter(Hit.90.Percent.Max == "Yes") %>%
  distinct(anon_id, Date) %>%
  group_by(Date) %>%
  summarise(daily_hits = n())

# Plot
ggplot(daily_90_counts, aes(x = Date, y = daily_hits)) +
  geom_line(color = "#CFB87C", linewidth = 1) +
  geom_smooth(method = "loess", se = FALSE, color = "#565A5C", linetype = "dashed") +
  labs(title = "Daily Count of Players Reaching ≥ 90% of Max Velocity",
       subtitle = "Over the 2024–25 Training Season",
       x = "Date", y = "Times reached ≥ 90%") +
  theme_classic()
```
Data is noisy, so lets try grouping by week instead of every day.

```{r}
# >90% counts for each week instead of each day. Will be a little less noisy than the daily
weekly_90_counts <- Catapult_Session_clean %>%
  filter(Date >= as.Date("2024-06-30") & Date <= as.Date("2025-07-01")) %>%
  filter(Hit.90.Percent.Max == "Yes") %>%
  distinct(anon_id, Date) %>%
  mutate(week = floor_date(Date, unit = "week")) %>%
  group_by(week) %>%
  summarise(weekly_hits = n())

ggplot(weekly_90_counts, aes(x = week, y = weekly_hits)) +
  geom_line(color = "#CFB87C", linewidth = 1) +
  geom_point(color = "#565A5C") +
  geom_hline(yintercept = mean(weekly_90_counts$weekly_hits), 
             linetype = "dashed", color = "#565A5C", linewidth = 0.6) +
  labs(title = "Weekly Count of Players Reaching ≥ 90% of Max Velocity",
       x = "Week", y = "Times reached ≥ 90%") +
  theme_classic()
```


```{r}
# Bar chart of weekly >90% counts

mean_val <- mean(weekly_90_counts$weekly_hits)

ggplot(weekly_90_counts, aes(x = week, y = weekly_hits)) +
  geom_col(fill = "#CFB87C", color = "#565A5C", width = 5) +
  geom_text(aes(label = weekly_hits), 
            vjust = -0.4, 
            size = 2.5, 
            color = "black") +
  geom_hline(yintercept = mean_val,
             linetype = "dashed", color = "#565A5C", linewidth = 0.5) +
  annotate("text", 
           x = min(weekly_90_counts$week) + 7,  # Adjust this date to place the label
           y = mean_val + 1.5,                 # Slightly above the line
           label = paste("Mean:", round(mean_val, 1)),
           size = 3.25, color = "#000000") +
  labs(
    title    = "Weekly Count of Players Reaching ≥ 90% of Max Velocity",
    subtitle = paste("Season Average per Week:", round(mean(weekly_90_counts$weekly_hits), 1)),
    x        = "Week",
    y        = "Times reached ≥ 90%"
  ) +
  scale_x_date(date_breaks = "2 weeks", date_labels = "%b %d") +
  theme_classic() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```
Some of our lowest average counts for a week seem to be during the season, whereas some of our highest counts seem to be pre and post-season.

## Should we consider the number of sprinting efforts that athletes are completing?

How often athletes are hitting which velocity bands in relation to their top speeds.

```{r}
# Create sum of weekly band totals

# Make sure week is defined
Catapult_Session_clean <- Catapult_Session_clean %>%
  filter(Date >= as.Date("2024-06-30") & Date <= as.Date("2025-07-01")) %>% 
  mutate(week = floor_date(Date, unit = "week"))

# Sum efforts by week and athlete
weekly_velocity_efforts <- Catapult_Session_clean %>%
  group_by(anon_id, week) %>%
  summarise(
    V2 = sum(Velocity.Band.2.Total.Effort.Count, na.rm = TRUE),
    V3 = sum(Velocity.Band.3.Total.Effort.Count, na.rm = TRUE),
    V4 = sum(Velocity.Band.4.Total.Effort.Count, na.rm = TRUE),
    V5 = sum(Velocity.Band.5.Total.Effort.Count, na.rm = TRUE),
    V6 = sum(Velocity.Band.6.Total.Effort.Count, na.rm = TRUE),
    V7 = sum(Velocity.Band.7.Total.Effort.Count, na.rm = TRUE),
    V8 = sum(Velocity.Band.8.Total.Effort.Count, na.rm = TRUE),
    total_efforts = V2 + V3 + V4 + V5 + V6 + V7 + V8,
    Weekly_Max_Velocity = max(Maximum.Velocity, na.rm = TRUE),
    Player_Max_Velocity = first(Player.Max.Velocity),
    .groups = "drop"
  ) %>%
  mutate(
    pct_of_max_velocity = (Weekly_Max_Velocity / Player_Max_Velocity) * 100
  )

# Create percentage of weekly efforts in each band
weekly_velocity_efforts <- weekly_velocity_efforts %>%
  mutate(
    pct_V2 = (V2 / total_efforts) * 100,
    pct_V3 = (V3 / total_efforts) * 100,
    pct_V4 = (V4 / total_efforts) * 100,
    pct_V5 = (V5 / total_efforts) * 100,
    pct_V6 = (V6 / total_efforts) * 100,
    pct_V7 = (V7 / total_efforts) * 100,
    pct_V8 = (V8 / total_efforts) * 100
  )

weekly_velocity_efforts <- weekly_velocity_efforts %>%
  filter(total_efforts > 0)
```


```{r}
# Plot for each player

# Loop over all players and display their plots
unique(weekly_velocity_efforts$anon_id) %>%
  lapply(function(player_id) {
    
    # Prepare the data for one player
    player_weekly_data <- weekly_velocity_efforts %>%
      filter(anon_id == player_id) %>%
      select(week, pct_V2:pct_V8, pct_of_max_velocity) %>%
      pivot_longer(
        cols = starts_with("pct_V"),
        names_to = "velocity_band",
        values_to = "percent_effort"
      ) %>%
      mutate(
        velocity_band = factor(
          velocity_band,
          levels = paste0("pct_V", 8:2),
          labels = paste0("V", 8:2)
        )
      )
    
    # Skip empty data
    if (nrow(player_weekly_data) == 0) return(NULL)
    
    # Generate and print the plot
    plot <- ggplot(player_weekly_data, aes(x = week)) +
      geom_col(aes(y = percent_effort, fill = velocity_band), position = "stack") +
      geom_line(aes(y = pct_of_max_velocity, group = 1), color = "black", size = 1.2) +
      geom_point(aes(y = pct_of_max_velocity), color = "black", size = 2) +
      scale_fill_manual(
        values = c(
          "V2" = "darkgreen",
          "V3" = "green2",
          "V4" = "greenyellow",
          "V5" = "yellow",
          "V6" = "orange",
          "V7" = "tomato",
          "V8" = "firebrick"
  )
) +
    scale_y_continuous(
        name = "Band Distribution (%)",
        sec.axis = sec_axis(~ ., name = "Weekly Max Velocity (% of PR)")
      ) +
      labs(
        title = paste("Velocity Band Effort % and Speed Trend for Player", player_id),
        x = "Week",
        fill = "Velocity Band"
      ) +
      theme_classic()
    
    print(plot)  # Display plot
    
    return(NULL)
  })
```

Each player is different in reaching different velocity bands in relation to their top speeds. Some players, ID_11 for example, rarely enter bands 6 or higher, even if they are close to 100% of their max velocity. This shows the issues with using absolute bands for the whole team.


```{r}
# Filter for ID_11 and reshape the data
player_weekly_data <- weekly_velocity_efforts %>%
  filter(anon_id == "ID_11") %>%
  select(week, pct_V2:pct_V8, pct_of_max_velocity) %>%
  pivot_longer(
    cols = starts_with("pct_V"),
    names_to = "velocity_band",
    values_to = "percent_effort"
  ) %>%
  mutate(
    velocity_band = factor(
      velocity_band,
      levels = paste0("pct_V", 8:2),
      labels = paste0("V", 8:2)
    )
  )

# Plot for ID_11
ggplot(player_weekly_data, aes(x = week)) +
  geom_col(aes(y = percent_effort, fill = velocity_band), position = "stack") +
  geom_line(aes(y = pct_of_max_velocity, group = 1), color = "black", size = 1.2) +
  geom_point(aes(y = pct_of_max_velocity), color = "black", size = 2) +
  scale_fill_manual(
    values = c(
      "V2" = "darkgreen",
      "V3" = "green2",
      "V4" = "greenyellow",
      "V5" = "yellow",
      "V6" = "orange",
      "V7" = "tomato",
      "V8" = "firebrick"
    )
  ) +
  scale_y_continuous(
    name = "Band Distribution (%)",
    sec.axis = sec_axis(~ ., name = "Weekly Max Velocity (% of PR)")
  ) +
  labs(
    title = "Velocity Band Effort % and Speed Trend for Player ID_11",
    x = "Week",
    fill = "Velocity Band"
  ) +
  theme_classic()
```


```{r}
# Pick one player
player_id <- "ID_93"

# Filter data for that player and weeks
player_data <- weekly_velocity_efforts %>%
  filter(anon_id == player_id)

# Plot of Total Sprinting Efforts per Week
ggplot(player_data, aes(x = week, y = total_efforts)) +
  geom_line(color = "#CFB87C", size = 1) +
  geom_point(color = "#CFB87C", size = 2) +
  labs(
    title = paste("Total Sprinting Efforts per Week for Player", player_id),
    x = "Week",
    y = "Total Sprinting Efforts"
  ) +
  theme_classic()

#Plot of Sprint Effort Distribution by Velocity Band

# Reshape absolute counts to long format
player_counts_long <- player_data %>%
  select(week, V2, V3, V4, V5, V6, V7, V8) %>%
  pivot_longer(
    cols = V2:V8,
    names_to = "velocity_band",
    values_to = "effort_count"
  ) %>%
  mutate(
    velocity_band = factor(velocity_band, levels = paste0("V", 8:2))
  )

ggplot(player_counts_long, aes(x = week, y = effort_count, fill = velocity_band)) +
  geom_col(position = "stack") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = paste("Sprint Effort Distribution by Velocity Band for Player", player_id),
    x = "Week",
    y = "Sprint Effort Count",
    fill = "Velocity Band"
  ) +
  theme_classic()
```
#### Exploring correlations between bands and max speeds

```{r}


# Select relevant columns
cor_data <- weekly_velocity_efforts %>%
  select(pct_of_max_velocity, pct_V2, pct_V3, pct_V4, pct_V5, pct_V6, pct_V7, pct_V8)

# Compute correlation matrix
cor_matrix <- cor(cor_data, use = "pairwise.complete.obs")

cor_matrix


# Compute correlations with pct_of_max_velocity
cor_values <- cor_data %>%
  summarise(across(-pct_of_max_velocity,
                   ~ cor(.x, cor_data$pct_of_max_velocity, use = "pairwise.complete.obs"))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "correlation")

# Plot with labels
ggplot(cor_values, aes(x = reorder(variable, correlation), y = correlation)) +
  geom_col(fill = "#CFB87C") +
  geom_text(aes(label = round(correlation, 2)), 
            hjust = ifelse(cor_values$correlation >= 0, -0.1, 1.1), 
            color = "black", size = 3) +
  coord_flip() +
  geom_hline(yintercept = 0, color = "black", linetype = "dashed") +
  labs(
    title = "Correlation Between Percent in Band and Percent of Max Velocity",
    x = "Band",
    y = "Pearson Correlation"
  ) +
  theme_classic() 
```
V4 and V5 appear to be slightly more predictive of top-speed achievement than V6, V7 or V8 — possibly because they're more frequently reached zones.

V2 has a moderately strong negative linear relationship with reaching top-speed. When athletes spend more effort in this low-speed band, their weekly top speed (as % of max) tends to be lower.

```{r}
# Linear model with all bands predicting pct_of_max_velocity
model_all_bands <- lm(
  pct_of_max_velocity ~ pct_V2 + pct_V3 + pct_V4 + pct_V5 + pct_V6 + pct_V7 + pct_V8,
  data = weekly_velocity_efforts
)
summary(model_all_bands)
```
```{r}
# Compute change in top speeds week-to-week
weekly_velocity_efforts <- weekly_velocity_efforts %>%
  arrange(anon_id, week) %>%
  group_by(anon_id) %>%
  mutate(
    pct_of_max_velocity_change = pct_of_max_velocity - lag(pct_of_max_velocity)
  ) %>%
  ungroup()
```

```{r}
# Scatterplot with smoothing line for V8 band effort

# Create V8 data set that only includes when someone was in V8 for a given week
V8 <- weekly_velocity_efforts %>%
  filter(pct_V8 > 0)

# Plot
ggplot(V8, aes(x = pct_V8, y = pct_of_max_velocity_change)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "darkred") +
  labs(
    title = "Change in Max Speed vs. V8 Band Usage",
    x = "Percent of Total Effort in V8 Band (%)",
    y = "Change in Max Speed from Prior Week (%)"
  ) +
  theme_classic()
```

```{r}
weekly_velocity_efforts <- weekly_velocity_efforts %>%
  group_by(anon_id) %>%
  mutate(
    lag_V2 = lag(V2),
    lag_V3 = lag(V3),
    lag_V4 = lag(V4),
    lag_V5 = lag(V5),
    lag_V6 = lag(V6),
    lag_V7 = lag(V7),
    lag_V8 = lag(V8),
    
    lag_pct_V2 = lag(pct_V2),
    lag_pct_V3 = lag(pct_V3),
    lag_pct_V4 = lag(pct_V4),
    lag_pct_V5 = lag(pct_V5),
    lag_pct_V6 = lag(pct_V6),
    lag_pct_V7 = lag(pct_V7),
    lag_pct_V8 = lag(pct_V8)
  ) %>%
  ungroup()
```

```{r}
# Maybe group by position

# Get Player positions
player_positions <- Catapult_Session_clean %>%
  select(anon_id, Primary.Position) %>%
  distinct()

# Join Position into weekly_velocity_efforts
weekly_velocity_efforts <- weekly_velocity_efforts %>%
  left_join(player_positions, by = "anon_id")

# Position groups
weekly_velocity_efforts <- weekly_velocity_efforts %>%
  mutate(
    Position_Group = case_when(
      Primary.Position %in% c("QB", "LB", "TE", "RB") ~ "COMBO",
      Primary.Position %in% c("OL", "DL", "DE") ~ "BIGS",
      Primary.Position %in% c("WR", "DB", "DB, WR") ~ "SKILL",
      TRUE ~ "OTHER"
    )
  ) %>%
  filter(Position_Group != "OTHER")

ggplot(weekly_velocity_efforts, aes(x = Position_Group, y = pct_of_max_velocity_change)) +
  geom_boxplot(fill = "skyblue", outlier.color = "red", outlier.size = 1.5) +
  labs(
    title = "Weekly Change in % of Max Velocity by Position",
    x = "Position",
    y = "% Change in Max Velocity"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
weekly_band_effort_by_group <- weekly_velocity_efforts %>%
  group_by(week, Position_Group) %>%
  summarise(
    mean_V2 = mean(V2, na.rm = TRUE),
    mean_V3 = mean(V3, na.rm = TRUE),
    mean_V4 = mean(V4, na.rm = TRUE),
    mean_V5 = mean(V5, na.rm = TRUE),
    mean_V6 = mean(V6, na.rm = TRUE),
    mean_V7 = mean(V7, na.rm = TRUE),
    mean_V8 = mean(V8, na.rm = TRUE),
    
    mean_lag_V2 = mean(lag_V2, na.rm = TRUE),
    mean_lag_V3 = mean(lag_V3, na.rm = TRUE),
    mean_lag_V4 = mean(lag_V4, na.rm = TRUE),
    mean_lag_V5 = mean(lag_V5, na.rm = TRUE),
    mean_lag_V6 = mean(lag_V6, na.rm = TRUE),
    mean_lag_V7 = mean(lag_V7, na.rm = TRUE),
    mean_lag_V8 = mean(lag_V8, na.rm = TRUE),
    
    mean_pct_V2 = mean(pct_V2, na.rm = TRUE),
    mean_pct_V3 = mean(pct_V3, na.rm = TRUE),
    mean_pct_V4 = mean(pct_V4, na.rm = TRUE),
    mean_pct_V5 = mean(pct_V5, na.rm = TRUE),
    mean_pct_V6 = mean(pct_V6, na.rm = TRUE),
    mean_pct_V7 = mean(pct_V7, na.rm = TRUE),
    mean_pct_V8 = mean(pct_V8, na.rm = TRUE),
    mean_weekly_max_velocity = mean(Weekly_Max_Velocity, na.rm = TRUE),
    mean_pct_max_velocity = mean(pct_of_max_velocity, na.rm = TRUE),
    mean_pct_max_velocity_change = mean(pct_of_max_velocity_change, na.rm = TRUE),
    n_players = n()
  ) %>%
  ungroup()
```


```{r}

# Pivot longer to get bands in one column for easier plotting
band_long <- weekly_band_effort_by_group %>%
  pivot_longer(
    cols = starts_with("mean_pct_V"),
    names_to = "velocity_band",
    values_to = "mean_pct_effort"
  ) %>%
  mutate(
    velocity_band = factor(velocity_band, levels = paste0("mean_pct_V", 2:8))
  )

ggplot(band_long, aes(x = week, y = mean_pct_effort, color = velocity_band)) +
  geom_line(size = 1) +
  facet_wrap(~ Position_Group) +
  labs(
    title = "Weekly Mean % Effort in Velocity Bands by Position Group",
    x = "Week",
    y = "Mean % Effort",
    color = "Velocity Band"
  ) +
   scale_color_manual(
        values = c(
          "mean_pct_V2" = "darkgreen",
          "mean_pct_V3" = "green2",
          "mean_pct_V4" = "greenyellow",
          "mean_pct_V5" = "yellow",
          "mean_pct_V6" = "orange",
          "mean_pct_V7" = "tomato",
          "mean_pct_V8" = "firebrick"
  )
) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

This shows the mean percent of total efforts in each band over weeks by each position group.

```{r}
# Plot mean weekly max velocity
ggplot(weekly_band_effort_by_group, aes(x = week, y = mean_weekly_max_velocity, color = Position_Group)) +
  geom_line(size = 1.2) +
  labs(
    title = "Mean Weekly Max Velocity by Position Group",
    x = "Week",
    y = "Mean Weekly Max Velocity"
  ) +
  theme_classic()


# Plot mean % max velocity change
ggplot(weekly_band_effort_by_group, aes(x = week, y = mean_pct_max_velocity_change, color = Position_Group)) +
  geom_line(size = 1.2) +
  labs(
    title = "Mean % Change in Max Velocity by Position Group",
    x = "Week",
    y = "Mean % Change in Max Velocity"
  ) +
  theme_classic()
```

```{r}
ggplot() +
  # Plot the stacked lines for band effort %
  geom_line(data = band_long, aes(x = week, y = mean_pct_effort, color = velocity_band), size = 1) +
  geom_line(data = weekly_band_effort_by_group,
            aes(x = week, y = mean_weekly_max_velocity),
            color = "black", size = 1.2) +

  facet_wrap(~ Position_Group) +
  labs(
    title = "Weekly Mean % Effort in Velocity Bands by Position Group\nwith Mean Weekly Max Velocity",
    x = "Week",
    y = "Mean % Effort",
    color = "Velocity Band"
  ) +
  scale_color_manual(
        values = c(
          "mean_pct_V2" = "darkgreen",
          "mean_pct_V3" = "green2",
          "mean_pct_V4" = "greenyellow",
          "mean_pct_V5" = "yellow",
          "mean_pct_V6" = "orange",
          "mean_pct_V7" = "tomato",
          "mean_pct_V8" = "firebrick"
  )
) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Define max effort and max velocity range
max_effort <- 67
max_velocity <- max(weekly_band_effort_by_group$mean_weekly_max_velocity, na.rm = TRUE)

ggplot() +
  geom_line(data = band_long, aes(x = week, y = mean_pct_effort, color = velocity_band), size = 1) +
  
  # Scale max_velocity to % effort scale to overlay on left axis
  geom_line(data = weekly_band_effort_by_group, 
            aes(x = week, y = (mean_weekly_max_velocity / max_velocity) * max_effort, color = "Max Velocity"),
            size = 1.1) +
  
  facet_wrap(~ Position_Group) +
  scale_y_continuous(
    name = "Mean % Effort",
    sec.axis = sec_axis(~ . * max_velocity / max_effort, name = "Mean Weekly Max Velocity (m/s)")
  ) +
  scale_color_manual(
    values = c(
      "mean_pct_V2" = "darkgreen",
      "mean_pct_V3" = "green2",
      "mean_pct_V4" = "greenyellow",
      "mean_pct_V5" = "yellow",
      "mean_pct_V6" = "orange",
      "mean_pct_V7" = "tomato",
      "mean_pct_V8" = "firebrick",
      "Max Velocity" = "black"
    )
  ) +
  labs(
    title = "Weekly Mean % Effort in Velocity Bands by Position Group\nwith Mean Weekly Max Velocity",
    x = "Week",
    color = "Velocity Band"
  ) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```



```{r}
# Modeling

# Separate by position group
bigs <- weekly_band_effort_by_group %>%
  filter(Position_Group == "BIGS")

skill <- weekly_band_effort_by_group %>%
  filter(Position_Group == "SKILL")

combo <- weekly_band_effort_by_group %>%
  filter(Position_Group == "COMBO")

# Bigs Model
model_bigs <- lm(
  mean_weekly_max_velocity ~ mean_lag_V2 + mean_lag_V3 + mean_lag_V4 + mean_lag_V5 + mean_lag_V6 + mean_lag_V7 + mean_lag_V8, data = bigs
  )
summary(model_bigs)

# Skill Model
model_skill <- lm(
  mean_weekly_max_velocity ~ mean_lag_V2 + mean_lag_V3 + mean_lag_V4 + mean_lag_V5 + mean_lag_V6 + mean_lag_V7 + mean_lag_V8, data = skill
  )
summary(model_skill)

# Combo Model
model_combo <- lm(
  mean_weekly_max_velocity ~ mean_lag_V2 + mean_lag_V3 + mean_lag_V4 + mean_lag_V5 + mean_lag_V6 + mean_lag_V7 + mean_lag_V8, data = combo)
summary(model_combo)
```

```{r}
# Group correlation:

# Select relevant variables
vars <- c("mean_weekly_max_velocity", "mean_lag_V2", "mean_lag_V3", 
          "mean_lag_V4", "mean_lag_V5", "mean_lag_V6", "mean_lag_V7", "mean_lag_V8")

# Correlation matrices
cor_bigs <- cor(bigs[, vars], use = "complete.obs")
cor_skill <- cor(skill[, vars], use = "complete.obs")
cor_combo <- cor(combo[, vars], use = "complete.obs")
round(cor_bigs, 2)
round(cor_skill, 2)
round(cor_combo, 2)
```


```{r}
# Reduce for better modeling
bigs <- bigs %>%
  mutate(
    low_band = (mean_lag_V2 + mean_lag_V3) / 2,
    mid_band = (mean_lag_V4 + mean_lag_V5 + mean_lag_V6) / 3,
    high_band = (mean_lag_V7 + mean_lag_V8) / 2
  )
model_bigs_simple <- lm(mean_weekly_max_velocity ~ low_band + mid_band + high_band, data = bigs)
summary(model_bigs_simple)


# Skill Group
skill <- skill %>%
  mutate(
    low_band = (mean_lag_V2 + mean_lag_V3 + mean_lag_V4) / 3,
    mid_band = (mean_lag_V5 + mean_lag_V6) / 2,
    high_band = (mean_lag_V7 + mean_lag_V8) / 2
  )
model_skill_simple <- lm(mean_weekly_max_velocity ~ low_band + mid_band + high_band, data = skill)
summary(model_skill_simple)

# Combo group
combo <- combo %>%
  mutate(
    low_band = (mean_lag_V2 + mean_lag_V3) / 2,
    mid_band = (mean_lag_V4 + mean_lag_V5) / 2,
    high_band = (mean_lag_V6 + mean_lag_V7 + mean_lag_V8) / 3
  )
model_combo_simple <- lm(mean_weekly_max_velocity ~ low_band + mid_band + high_band, data = combo)
summary(model_combo_simple)
```
Bigs model:
  Statistically significant overall and explains around 33% of the variation of max velocity. The low band is significantly negative. Every unit increase in the low band results in a decrease in max velocity. The mid and high bands are not significant but the high band shows a positive trend.
  Based on this model, for bigs, more low-band effort may reduce weekly top speed, possibly indicating underexposure of high speeds. High-band efforts might help, but aren’t clearly impactful in this group.

Skill model:
  Almost significant. Low band has a negative effect, mid band has a positive effect, and high band is not significant. 
  Based on this model, for skill players, more low-intensity exposure seems detrimental to max speed, while moderate band (V5–V6) exposure may enhance it.
  
Combo model:
  Model is not significant. The combo position group contains many different type of positions (QBs, RBs, TEs, LBs) with different movement and velocities. This variability may obscure relationships.
  
Across groups, low-band exposure is consistently negatively related to peak weekly speed — suggesting that too much low-intensity work may reduce the capacity to reach high speeds.

## Are relative efforts and bands more advantageous than the absolute bands provided?

Look at ID_11's plot from the last question. This player is an offensive lineman. Looking at the plot, he is mostly in band 2 and 3 while never reaching bands 7 or 8 and rarely reaching band 6. Despite this, this athlete's weekly max velocity is always at least 75% of their all-time max velocity. Only looking at the absolute bands that are provided, we might come to the conclusion that ID_11 is not achieving high running speeds, however after looking at his max velocity efforts relative to his all-time max velocity, he is reaching high running speeds.

#### Create Relative Bands for ID_11

```{r}
# Create Relative Bands for ID_11

# Prepare ID_11 dataset with relative bands
ID_11 <- Catapult_Session_clean %>%
  filter(Date >= as.Date("2024-06-30") & Date <= as.Date("2025-07-01")) %>% 
  filter(anon_id == "ID_11", Maximum.Velocity != 0) %>%
  filter(!is.na(Maximum.Velocity)) %>%
  mutate(
    week = floor_date(Date, unit = "week"),
    pct_of_max = (Maximum.Velocity / Player.Max.Velocity) * 100,
    # Create Relative Bands
    relative_band = cut(
      pct_of_max,
      breaks = c(0, 40, 50, 60, 70, 80, 90, 100),
      labels = c("V2 (<40%)", "V3 (40-50%)","V4 (50-60%)" ,"V5 (60-70%)", "V6 (70-80%)", "V7 (80-90%)", "V8 (90-100%)"),
      right = TRUE, # Set to TRUE to include 100% in band
      include.lowest = TRUE  # Includes 0 in first band
    ),
    # Reverse factor levels so highest band is on top in plot
  relative_band = factor(
    relative_band,
    levels = rev(c("V2 (<40%)", "V3 (40-50%)","V4 (50-60%)" ,"V5 (60-70%)", "V6 (70-80%)", "V7 (80-90%)", "V8 (90-100%)"))
  )
  )

# Summarize counts per week and relative band
weekly_effort <- ID_11 %>%
  group_by(week, relative_band) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(week) %>%
  mutate(pct_effort = (count / sum(count)) * 100) %>%
  ungroup()

# Pivot wider to get percentages per band as columns
weekly_effort_wide <- weekly_effort %>%
  select(week, relative_band, pct_effort) %>%
  pivot_wider(names_from = relative_band, values_from = pct_effort, values_fill = 0)

# Calculate weekly max velocity % of player max velocity
weekly_max_velocity <- ID_11 %>%
  group_by(week) %>%
  summarise(pct_of_max_velocity = max(pct_of_max), .groups = "drop")

# Join the max velocity % back to wide effort data
weekly_effort_wide <- weekly_effort_wide %>%
  left_join(weekly_max_velocity, by = "week")

# Pivot longer for stacked bar plotting
weekly_effort_long <- weekly_effort_wide %>%
  pivot_longer(
    cols = c("V2 (<40%)", "V3 (40-50%)","V4 (50-60%)" ,"V5 (60-70%)", "V6 (70-80%)", "V7 (80-90%)", "V8 (90-100%)"),
    names_to = "relative_band",
    values_to = "pct_effort"
  ) %>%
  mutate(
    relative_band = factor(
      relative_band,
      levels = rev(c("V2 (<40%)", "V3 (40-50%)","V4 (50-60%)" ,"V5 (60-70%)", "V6 (70-80%)", "V7 (80-90%)", "V8 (90-100%)"))
    )
  )
```

```{r}
# Plot Relative Bands for ID_11
ggplot(weekly_effort_long, aes(x = week, y = pct_effort, fill = relative_band)) +
  geom_col(position = "stack") +
  geom_line(aes(y = pct_of_max_velocity, group = 1), 
            color = "black", size = 1.2) +
  geom_point(aes(y = pct_of_max_velocity), 
             color = "black", size = 2) +
  scale_fill_manual(
    values = c(
      "V2 (<40%)" = "darkgreen",
      "V3 (40-50%)" = "green2",
      "V4 (50-60%)" = "greenyellow",
      "V5 (60-70%)" = "yellow",
      "V6 (70-80%)" = "orange",
      "V7 (80-90%)" = "tomato",
      "V8 (90-100%)" = "darkred"
    )
  ) +
  labs(
    title = "Relative Velocity Band Effort % per Week, ID_11",
    x = "Week",
    y = "Percent of Weekly Efforts",
    fill = "Relative Velocity Band"
  ) + 
  scale_y_continuous(
    sec.axis = sec_axis(~ ., name = "Percent of Max Velocity")
  ) +
  theme_classic()
```
Comparing this with the absolute bands graph of ID_11, we can see that this is a much better representation of their running speeds.

#### Relative Bands for each athlete

```{r}
# Function to create relative bands and plot these for each athlete

# Arrange data so that the plot will display in anon_id order
clean_anons <- Catapult_Session_clean %>%
  arrange(anon_id)

# Loop over all athletes and create their relative bands plots
unique(clean_anons$anon_id) %>%
  lapply(function(player_id) {
    # Prepare data for player
    player_data <- Catapult_Session_clean %>%
      filter(Date >= as.Date("2024-06-30") & Date <= as.Date("2025-07-01")) %>%
      filter(anon_id == player_id, Maximum.Velocity != 0, !is.na(Maximum.Velocity)) %>%
      mutate(
        week = floor_date(Date, unit = "week"),
        pct_of_max = (Maximum.Velocity / Player.Max.Velocity) * 100,
        # Create Relative Bands
        relative_band = cut(
          pct_of_max,
          breaks = c(0, 40, 50, 60, 70, 80, 90, 100),
          labels = c("V2 (<40%)", "V3 (40-50%)", "V4 (50-60%)", "V5 (60-70%)",
                     "V6 (70-80%)", "V7 (80-90%)", "V8 (90-100%)"),
          right = TRUE, # Set to true to include 100%
          include.lowest = TRUE  # Set to true to include 0 in 1st interval
        ),
        # Reverse factor levels so highest band is on top in plot
        relative_band = factor(
          relative_band,
          levels = rev(c("V2 (<40%)", "V3 (40-50%)", "V4 (50-60%)", "V5 (60-70%)",
                         "V6 (70-80%)", "V7 (80-90%)", "V8 (90-100%)"))
        )
      )
    
    if (nrow(player_data) == 0) return(NULL)  # skip empty

    # Summarize counts per week and relative band
    weekly_effort <- player_data %>%
      group_by(week, relative_band) %>%
      summarise(count = n(), .groups = "drop") %>%
      group_by(week) %>%
      mutate(pct_effort = (count / sum(count)) * 100) %>%
      ungroup()

    # Pivot wider to get percentages per band as columns
    weekly_effort_wide <- weekly_effort %>%
      select(week, relative_band, pct_effort) %>%
      pivot_wider(names_from = relative_band, values_from = pct_effort, values_fill = 0)

    # Calculate weekly max velocity % of player max velocity
    weekly_max_velocity <- player_data %>%
      group_by(week) %>%
      summarise(pct_of_max_velocity = max(pct_of_max), .groups = "drop")

    # Join
    weekly_effort_wide <- weekly_effort_wide %>%
      left_join(weekly_max_velocity, by = "week")
    
    # Pivot longer for stacked bar plotting
    weekly_effort_long <- weekly_effort_wide %>%
      pivot_longer(
          cols = -c(week, pct_of_max_velocity),
        names_to = "relative_band",
        values_to = "pct_effort"
      ) %>%
      mutate(
        relative_band = factor(
          relative_band,
          levels = rev(c("V2 (<40%)", "V3 (40-50%)", "V4 (50-60%)", "V5 (60-70%)",
                         "V6 (70-80%)", "V7 (80-90%)", "V8 (90-100%)"))
        )
      )
    
    # Plot
    plot <- ggplot(weekly_effort_long, aes(x = week, y = pct_effort, fill = relative_band)) +
      geom_col(position = "stack") +
      geom_line(aes(y = pct_of_max_velocity, group = 1), color = "black", size = 1.2) +
      geom_point(aes(y = pct_of_max_velocity), color = "black", size = 2) +
      scale_fill_manual(
        values = c(
          "V2 (<40%)" = "darkgreen",
          "V3 (40-50%)" = "green2",
          "V4 (50-60%)" = "greenyellow",
          "V5 (60-70%)" = "yellow",
          "V6 (70-80%)" = "orange",
          "V7 (80-90%)" = "tomato",
          "V8 (90-100%)" = "darkred"
        )
      ) +
      scale_y_continuous(
        name = "Percent of Weekly Effort",
        sec.axis = sec_axis(~ ., name = "Percent of Max Velocity")
      ) +
      labs(
        title = paste("Relative Velocity Band Effort % and Max Velocity Trend for Player", player_id),
        x = "Week",
        fill = "Relative Velocity Band"
      ) +
      theme_classic()

    print(plot)
    
    return(NULL)
  })
```


```{r}
# Create relative bands for all athletes

# Define the velocity band labels
band_levels <- c("V2 (<40%)", "V3 (40-50%)", "V4 (50-60%)", "V5 (60-70%)",
                     "V6 (70-80%)", "V7 (80-90%)", "V8 (90-100%)")

# Create exposure data frame for all players
weekly_sprint_exposure <- Catapult_Session_clean %>%
  filter(Date >= as.Date("2024-06-30") & Date <= as.Date("2025-07-01")) %>%
  filter(Maximum.Velocity != 0, !is.na(Maximum.Velocity)) %>%
  mutate(
    week = floor_date(Date, unit = "week"),
    pct_of_max = (Maximum.Velocity / Player.Max.Velocity) * 100,
    relative_band = cut(
      pct_of_max,
      breaks = c(0, 40, 50, 60, 70, 80, 90, 100.1),
      labels = band_levels,
      right = TRUE,  # will include 100
      include.lowest = TRUE
    ),
    relative_band = factor(relative_band, levels = band_levels)
  ) %>%
  group_by(anon_id, week, relative_band) %>%
  summarise(effort_count = n(), .groups = "drop") %>%
  group_by(anon_id, week) %>%
  mutate(
    total_efforts = sum(effort_count),
    pct_effort = (effort_count / total_efforts) * 100
  ) %>%
  ungroup() %>%
  select(anon_id, week, relative_band, pct_effort) %>%
  pivot_wider(
    names_from = relative_band,
    values_from = pct_effort,
    values_fill = 0
  )

# Add weekly max velocity % of max
weekly_max_pct <- Catapult_Session_clean %>%
  filter(Date >= as.Date("2024-06-30") & Date <= as.Date("2025-07-01")) %>%
  filter(Maximum.Velocity != 0, !is.na(Maximum.Velocity)) %>%
  mutate(
    week = floor_date(Date, unit = "week"),
    pct_of_max = (Maximum.Velocity / Player.Max.Velocity) * 100
  ) %>%
  group_by(anon_id, week) %>%
  summarise(pct_of_max_velocity = max(pct_of_max, na.rm = TRUE), .groups = "drop")

# Final data set
relative_bands <- weekly_sprint_exposure %>%
  left_join(weekly_max_pct, by = c("anon_id", "week"))

# Convert to long for plotting
relative_bands_long <- relative_bands %>%
  pivot_longer(
    cols = starts_with("V"),
    names_to = "relative_band",
    values_to = "pct_effort"
  ) %>%
  mutate(
    relative_band = factor(relative_band, levels = band_levels)
  )
```

```{r}
COMBO <- c("QB","LB","TE","RB", "ILB")
BIG <- c("OL", "DL", "DE", "DT")
SKILL <- c("WR", "DB", "CB", "SAF")
Positions <- c("COMBO", "BIG", "SKILL")

weekly_sprint_exposure <- left_join(weekly_sprint_exposure,player_positions, by = "anon_id", relationship = "many-to-many")

weekly_sprint_exposure <- weekly_sprint_exposure %>%
  mutate(Position = case_when(Primary.Position %in% COMBO ~ "COMBO",
                               Primary.Position %in% BIG ~ "BIG",
                               Primary.Position %in% SKILL ~ "SKILL"))

weekly_sprint_exposure <- distinct(weekly_sprint_exposure)

max_velocities <- weekly_velocity_efforts[,c("anon_id","week","pct_of_max_velocity")]

weekly_sprint_exposure <- left_join(weekly_sprint_exposure, max_velocities, by = c("anon_id", "week"), relationship="many-to-many")




sprint_exposure_big <- weekly_sprint_exposure %>%
  filter(Position == "BIG") %>%
  group_by(week) %>%
  mutate(avg_pct_max = mean(pct_of_max_velocity),
         avg_V8 = mean(`V8 (90-100%)`),
         avg_V7 = mean(`V7 (80-90%)`),
         avg_V6 = mean(`V6 (70-80%)`),
         avg_V5 = mean(`V5 (60-70%)`),
         avg_V4 = mean(`V4 (50-60%)`),
         avg_V3 = mean(`V3 (40-50%)`),
         avg_V2 = mean(`V2 (<40%)`)) %>%
  ungroup() %>%
  na.omit()

sprint_exposure_combo <- weekly_sprint_exposure %>%
  filter(Position == "COMBO")  %>%
  group_by(week) %>%
  mutate(avg_pct_max = mean(pct_of_max_velocity),
         avg_V8 = mean(`V8 (90-100%)`),
         avg_V7 = mean(`V7 (80-90%)`),
         avg_V6 = mean(`V6 (70-80%)`),
         avg_V5 = mean(`V5 (60-70%)`),
         avg_V4 = mean(`V4 (50-60%)`),
         avg_V3 = mean(`V3 (40-50%)`),
         avg_V2 = mean(`V2 (<40%)`)) %>%
  ungroup() %>%
  na.omit()

sprint_exposure_skill <- weekly_sprint_exposure %>%
  filter(Position == "SKILL")  %>%
  group_by(week) %>%
  mutate(avg_pct_max = mean(pct_of_max_velocity),
         avg_V8 = mean(`V8 (90-100%)`),
         avg_V7 = mean(`V7 (80-90%)`),
         avg_V6 = mean(`V6 (70-80%)`),
         avg_V5 = mean(`V5 (60-70%)`),
         avg_V4 = mean(`V4 (50-60%)`),
         avg_V3 = mean(`V3 (40-50%)`),
         avg_V2 = mean(`V2 (<40%)`)) %>%
  ungroup() %>%
  na.omit()
  
```

When I built the models that considered the relative bands instead of the absolute bands provided, I found that initially, the results were a lot better than the previous models with the absolute bands. This suggests that the relative bounds which are segmented into 10% chunks of all time maximum velocity for each player is a lot more indicative of effort and therefore their percentage of maximum velocity in a given week. We are able to see though that there is a lot of multicollinearity within the relative bands calculated. 

```{r}
# Modeling

# Bigs Model
model_big <- lm(avg_pct_max~avg_V2+avg_V3+avg_V4+avg_V5+avg_V6+avg_V7+avg_V8,
                data=sprint_exposure_big)
summary(model_big)


# Skill Model
model_skill <- lm(avg_pct_max~avg_V2+avg_V3+avg_V4+avg_V5+avg_V6+avg_V7+avg_V8,
                data=sprint_exposure_skill)
summary(model_skill)


# Combo Model
model_combo <- lm(avg_pct_max~avg_V2+avg_V3+avg_V4+avg_V5+avg_V6+avg_V7+avg_V8,
               data=sprint_exposure_combo)
summary(model_combo)

```

Looking at the correlations between all of the predictors as well as the response variable in the model we can see that a lot of the predictors have super strong correlations which each other, some more so than they are with the response. This suggests that the issue with the models above is that multicollinearity is bogging them down and we are not seeing the true relationships between the predictors and the response. 

```{r Looking at collinear predictors}
cor(sprint_exposure_big[,13:20])
cor(sprint_exposure_skill[,13:20])
cor(sprint_exposure_combo[,13:20])
```

All of the models below are the best 3 predictor models that resulted for each position after running the best subsets algorithm. All of the following have reductions in adjusted-$R^2$ but they don't seem significant considering that we took out over half of the predictors and maintained a relatively similar adjusted-$R^2$ value. 

```{r running best subsets on the models to limit collinearity}
#Bigs

#best_sub_big <- regsubsets(avg_pct_max~avg_V2+avg_V3+avg_V4+avg_V5+avg_V6+avg_V7+avg_V8,
#                data=sprint_exposure_big, method="exhaustive")
#summary(best_sub_big)

model_big <- lm(avg_pct_max~avg_V2+avg_V6+avg_V7,
                data=sprint_exposure_big)
summary(model_big)


#Skills

#best_sub_skill <- regsubsets(avg_pct_max~avg_V2+avg_V3+avg_V4+avg_V5+avg_V6+avg_V7+avg_V8,
#                data=sprint_exposure_skill, method="exhaustive")
#summary(best_sub_skill)

model_skill <- lm(avg_pct_max~avg_V2+avg_V5+avg_V6,
                data=sprint_exposure_skill)
summary(model_skill)

#Combos
#best_sub_combo <- regsubsets(avg_pct_max~avg_V2+avg_V3+avg_V4+avg_V5+avg_V6+avg_V7+avg_V8,
#                data=sprint_exposure_combo, method="exhaustive")
#summary(best_sub_combo)

model_combo <- lm(avg_pct_max~avg_V2+avg_V4+avg_V5,
               data=sprint_exposure_combo)
summary(model_combo)
```
Since the models perform roughly the same with just 3 predictors as they do with all 7, it may make sense to instead truncate into more general bins. This may help us understand the relationship with low, medium and high effort with weekly maximum velocity. 

```{r}
sprint_exposure_big <- sprint_exposure_big %>%
  mutate(avg_low = (avg_V2+avg_V3)/2,
         avg_medium = (avg_V4+avg_V5+avg_V6)/3,
         avg_high = (avg_V7+avg_V8)/2)

sprint_exposure_skill <- sprint_exposure_skill %>%
  mutate(avg_low = (avg_V2+avg_V3)/2,
         avg_medium = (avg_V4+avg_V5+avg_V6)/3,
         avg_high = (avg_V7+avg_V8)/2)

sprint_exposure_combo <- sprint_exposure_combo %>%
  mutate(avg_low = (avg_V2+avg_V3)/2,
         avg_medium = (avg_V4+avg_V5+avg_V6)/3,
         avg_high = (avg_V7+avg_V8)/2)
```


```{r}
#bigs
model_big_general <- lm(avg_pct_max~avg_low+avg_medium+avg_high,
                        data=sprint_exposure_big)
summary(model_big_general)

#skills
model_skill_general <- lm(avg_pct_max~avg_low+avg_medium+avg_high,
                        data=sprint_exposure_skill)
summary(model_skill_general)

#combos
model_combo_general <- lm(avg_pct_max~avg_low+avg_medium+avg_high,
                        data=sprint_exposure_combo)
summary(model_combo_general)
```
Still pretty bad, I am going to use principle components regression to see if there are other relationships we are missing

```{r}
preds <- sprint_exposure_big[,14:20]

pc_loadings <- prcomp(preds, scale=TRUE)$rotation[,c(1,2,3)]
pc_loadings
```


## How does sprinting exposure (# of efforts, % max reached) relate to incidence of hamstring injuries?

```{r}
# Join relative_bands data set with injury data

Incident_dates <- Incident_Report_clean %>%
  filter(Date >= as.Date("2024-06-30") & Date <= as.Date("2025-07-01"))

# Get ids of athletes with injury
injured_ids <- unique(Incident_dates$anon_id)

# Filter relative_bands to only include athletes who got injured
injured_data <- relative_bands_long %>%
  filter(anon_id %in% injured_ids)

# Create injury weeks
injury_weeks <- Incident_Report_clean %>%
  mutate(
    week = floor_date(as.Date(Date.of.Injury), unit = "week")
  ) %>%
  filter(Date.of.Injury >= as.Date("2024-06-30") & Date.of.Injury <= as.Date("2025-07-01")) %>%
  select(anon_id, week) %>%
  distinct() %>%
  mutate(injury = 1)

injuries_and_running <- injured_data %>%
  left_join(injury_weeks, by = c("anon_id", "week")) %>%
  mutate(injury = ifelse(is.na(injury), 0, injury))
```


```{r}

injuries_and_running <- injuries_and_running %>%
  mutate(relative_band = factor(relative_band, levels = band_levels))


# Filter to only include players 194 and 285
selected_players <- c(194, 285)
plot_data <- injuries_and_running %>%
  filter(anon_id %in% selected_players)

# Identify injury weeks for shading
injury_shading <- plot_data %>%
  filter(injury == 1) %>%
  mutate(
    xmin = week - 3,
    xmax = week + 3,
    ymin = -Inf,
    ymax = Inf
  )

# Create a single faceted plot
ggplot(plot_data, aes(x = week)) +
  geom_rect(data = injury_shading,
            aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),
            fill = "blue", alpha = 0.2, inherit.aes = FALSE) +
  geom_col(aes(y = pct_effort, fill = relative_band), position = position_stack(reverse = TRUE)) +
  geom_line(aes(y = pct_of_max_velocity, group = 1), color = "black", size = 1.2) +
  geom_point(aes(y = pct_of_max_velocity), color = "black", size = 2) +
  facet_wrap(~ anon_id, scales = "free_x") +
  scale_fill_manual(
    values = c(
      "V2 (<40%)" = "darkgreen",
      "V3 (40-50%)" = "green2",
      "V4 (50-60%)" = "greenyellow",
      "V5 (60-70%)" = "yellow",
      "V6 (70-80%)" = "orange",
      "V7 (80-90%)" = "tomato",
      "V8 (90-100%)" = "darkred"
    )
  ) +
  scale_y_continuous(
    name = "Percent of Weekly Effort",
    sec.axis = sec_axis(~ ., name = "Percent of Max Velocity")
  ) +
  labs(
    title = "Velocity Band Exposure & Max % for Injured Players 194 and 285",
    x = "Week",
    fill = "Relative Velocity Band"
  ) +
  theme_classic()

```


```{r}
# Loop over injured athletes and create their plots

unique(injuries_and_running$anon_id) %>%
  lapply(function(player_id) {
    
    # Filter data for this player
    plot_data <- injuries_and_running %>%
      filter(anon_id == player_id)
    
    if (nrow(plot_data) == 0) return(NULL)  # Skip if no data
    
    # Get injury weeks
    injury_week_nums <- plot_data %>%
      filter(injury == 1) %>%
      pull(week)
    
    # Plot
    plot <- ggplot(plot_data, aes(x = week)) +
      # Highlight injury weeks with shaded blue areas
      geom_rect(data = data.frame(week = injury_week_nums),
                aes(xmin = week - 3, xmax = week + 3, ymin = -Inf, ymax = Inf),
                fill = "blue", alpha = 0.2, inherit.aes = FALSE) +
      geom_col(aes(y = pct_effort, fill = relative_band), position = position_stack(reverse = TRUE)) +
      geom_line(aes(y = pct_of_max_velocity, group = 1), color = "black", size = 1.2) +
      geom_point(aes(y = pct_of_max_velocity), color = "black", size = 2) +
      scale_fill_manual(
        values = c(
          "V2 (<40%)" = "darkgreen",
          "V3 (40-50%)" = "green2",
          "V4 (50-60%)" = "greenyellow",
          "V5 (60-70%)" = "yellow",
          "V6 (70-80%)" = "orange",
          "V7 (80-90%)" = "tomato",
          "V8 (90-100%)" = "darkred"
        )
      ) +
      scale_y_continuous(
        name = "Percent of Weekly Effort",
        sec.axis = sec_axis(~ ., name = "Percent of Max Velocity")
      ) +
      labs(
        title = paste("Velocity Band Exposure & Max % for Injured Player", player_id),
        x = "Week",
        fill = "Relative Velocity Band"
      ) +
      theme_classic()
    
    print(plot)
    
    return(NULL)
  })
```
The blue lines indicate a week where an injury occurred.
No real insights can be made from looking at relative velocity bands and injury occurrances. 

```{r}
model_injury <- glm(injury ~ pct_of_max_velocity,
                    data = injuries_and_running,
                    family = "binomial")

summary(model_injury)
```
Simple model
Each 1 percentage point increase in pct_of_max_velocity increases the log-odds of injury by 0.0106.
Not significant.


```{r}
# Get summary stats for both injury and non injury

# Clean and get date format
injuries_and_running_clean <- injuries_and_running %>%
  mutate(week_formatted = format(as.Date(week), "%m-%d-%Y")) %>%
  distinct(anon_id, week, .keep_all = TRUE)

# Filter for only injury weeks
injury_weeks <- injuries_and_running_clean %>%
  filter(injury == 1) %>%
  mutate(injury_event = paste0(anon_id, "__", week_formatted))

# Calculate statistics for injury weeks
injury_mean <- mean(injury_weeks$pct_of_max_velocity, na.rm = TRUE)

injury_summary_stats <- injury_weeks %>%
  summarise(
    mean_pct = mean(pct_of_max_velocity, na.rm = TRUE),
    sd_pct = sd(pct_of_max_velocity, na.rm = TRUE),
    n = sum(!is.na(pct_of_max_velocity))
  )
# Confidence interval 
se <- injury_summary_stats$sd_pct / sqrt(injury_summary_stats$n)
t_crit <- qt(0.975, df = injury_summary_stats$n - 1)
lower <- injury_summary_stats$mean_pct - t_crit * se
upper <- injury_summary_stats$mean_pct + t_crit * se
# Print
cat("95% CI for mean pct_of_max_velocity:", round(lower,2), "-", round(upper,2))


# Filter for non-injury weeks
non_injury_weeks <- injuries_and_running_clean %>%
  filter(injury == 0)

# Get statistics for non-injury weeks
non_injury_mean <- mean(non_injury_weeks$pct_of_max_velocity, na.rm = TRUE)

non_injury_summary_stats <- non_injury_weeks %>%
  summarise(
    mean_pct = mean(pct_of_max_velocity, na.rm = TRUE),
    sd_pct = sd(pct_of_max_velocity, na.rm = TRUE),
    n = sum(!is.na(pct_of_max_velocity))
  )

# Confidence interval
non_injury_se <- non_injury_summary_stats$sd_pct / sqrt(non_injury_summary_stats$n)
non_injury_t_crit <- qt(0.975, df = non_injury_summary_stats$n - 1)
non_injury_lower <- non_injury_summary_stats$mean_pct - non_injury_t_crit * non_injury_se
non_injury_upper <- non_injury_summary_stats$mean_pct + non_injury_t_crit * non_injury_se

# Print results
cat("95% CI for mean pct_of_max_velocity (non-injury weeks):", 
    round(non_injury_lower, 2), "-", round(non_injury_upper, 2))
```

```{r}
# T-test to compare pct_of_max_velocity in injuries and non injuries that week
t_test <- t.test(
  pct_of_max_velocity ~ injury, 
  data = injuries_and_running_clean,
  var.equal = FALSE # use TRUE if you assume equal variances
)

# Print results
print(t_test)
```
Group 1 (injury) mean = 86.55
Group 2 (non-injury) mean = 85.49
While the mean % of max velocity is higher for the injury group, the difference is small and not statistcally significant. (high p-value, 0.6)


```{r}  
# Plot of % Max Velocity during injury and non injury weeks
ggplot(injuries_and_running_clean, aes(x = week, y = pct_of_max_velocity)) +
  geom_point(aes(color = factor(injury))) +
  scale_color_manual(values = c("0" = "black", "1" = "red"),
                     labels = c("No Injury", "Injury"),
                     name = "Injury Status") +
  labs(
    title = "Percent of Max Velocity by Week",
    subtitle = paste("Mean % of Max Velocity, Injury: ", round(injury_mean, 2), " |  Mean % of Max Velocity, Non-Injury: ", round(non_injury_mean, 2)),
    x = "Week",
    y = "% of Max Velocity Reached"
  ) +
  theme_classic()


ggplot(injury_weeks, aes(x = week, y = pct_of_max_velocity)) +
  geom_point(color = "red") +
  labs(
    title = "Percent of Max Velocity During Injury Weeks",
    subtitle = paste("% of Max Velocity Mean: ", round(injury_mean, 2)),
    x = "Week",
    y = "% of Max Velocity"
  ) +
  theme_classic()

# Create bar chart
ggplot(injury_weeks, aes(x = factor(injury_event), y = pct_of_max_velocity)) +
  geom_col(fill = "#CFB87C") +
  geom_text(aes(label = round(pct_of_max_velocity, 1)),  # round to 1 decimal place
            vjust = -0.5, size = 2.75) +
  labs(
    title = "Percent of Max Velocity During Injury Weeks",
    subtitle = paste("Mean: ", round(injury_mean, 2)),
    x = "Injury Event",
    y = "% of Max Velocity"
  ) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r}
# Looking into weeks before injury

# Calculate percent of max velocity from 1, 2, and 3 weeks prior as well as the sum of weeks 1 and 2 and the sum of weeks 1, 2, and 3 as well as the change between week one and week 2
week_prior <- injuries_and_running_clean %>%
  group_by(anon_id) %>%
  arrange(week) %>%
  mutate(
    # Previous weeks values of % of max velocity
    lag1_pct_of_max_velocity = lag(pct_of_max_velocity, 1),
    lag2_pct_of_max_velocity = lag(pct_of_max_velocity, 2),
    lag3_pct_of_max_velocity = lag(pct_of_max_velocity, 3),
    
    # Change of % of max from current week to previous weeks
    change_lastweek = pct_of_max_velocity - lag1_pct_of_max_velocity,
    change_last2weeks = pct_of_max_velocity - lag2_pct_of_max_velocity,
    change_last3weeks = pct_of_max_velocity - lag3_pct_of_max_velocity,
    
    # Sum % of max of current to previous weeks
    sum_lastweek = pct_of_max_velocity + lag1_pct_of_max_velocity,
    sum_last2weeks = pct_of_max_velocity + lag1_pct_of_max_velocity + lag2_pct_of_max_velocity,
    sum_last3weeks = pct_of_max_velocity + lag1_pct_of_max_velocity + lag2_pct_of_max_velocity + lag3_pct_of_max_velocity,
    
    # Change between weeks (not current week)
    change_weeks1_2 = lag1_pct_of_max_velocity - lag2_pct_of_max_velocity,
    change_weeks1_3 = lag1_pct_of_max_velocity - lag3_pct_of_max_velocity,
    
    # Sum of weeks (not current week)
    sum_weeks1_2 = lag1_pct_of_max_velocity + lag2_pct_of_max_velocity,
    sum_weeks1_2_3 = lag1_pct_of_max_velocity + lag2_pct_of_max_velocity + lag3_pct_of_max_velocity
    ) %>%
  ungroup()

# Get Injury Event variable and Injury dataset
injury_week_prior <- week_prior %>%
  filter(injury == 1) %>%
  mutate(injury_event = paste0(anon_id, "__", week_formatted))

# Get non-injury dataset
non_injury_week_prior <- week_prior %>%
  filter(injury == 0)

# Get Means
means_injury <- injury_week_prior %>%
  drop_na(lag1_pct_of_max_velocity)
injury_week_prior_mean <- mean(means_injury$lag1_pct_of_max_velocity)
mean_noninjury <- non_injury_week_prior %>%
  drop_na(lag1_pct_of_max_velocity)
non_injury_week_prior_mean <- mean(mean_noninjury$lag1_pct_of_max_velocity)
injury_week_prior_mean
non_injury_week_prior_mean



# Plot of % Max Velocity during injury and non injury weeks
ggplot(week_prior, aes(x = week, y = lag1_pct_of_max_velocity)) +
  geom_point(aes(color = factor(injury))) +
  scale_color_manual(values = c("0" = "black", "1" = "red"),
                     labels = c("No Injury", "Injury"),
                     name = "Injury Status") +
  labs(
    title = "Percent of Max Velocity of Prior Week",
    subtitle = paste("Mean % of Max Velocity, Injury: ", round(injury_week_prior_mean, 2), " |  Mean % of Max Velocity, Non-Injury: ", round(non_injury_week_prior_mean, 2)),
    x = "Week",
    y = "% of Max Velocity Reached"
  ) +
  theme_classic()


ggplot(injury_week_prior, aes(x = week, y = lag1_pct_of_max_velocity)) +
  geom_point(color = "red") +
  labs(
    title = "Percent of Max Velocity the week before injury",
    subtitle = paste("% of Max Velocity Mean: ", round(injury_week_prior_mean, 2)),
    x = "Week",
    y = "% of Max Velocity"
  ) +
  theme_classic()

# Bar chart for week prior to injury % Max
ggplot(injury_week_prior, aes(x = factor(injury_event), y = lag1_pct_of_max_velocity)) +
  geom_col(fill = "#CFB87C") +
  geom_text(aes(label = round(pct_of_max_velocity, 1)),  # round to 1 decimal place
            vjust = -0.5, size = 2.75) +
  labs(
    title = "Percent of Max Velocity the Week Before Injury",
    subtitle = paste("% Max Mean: ", round(injury_week_prior_mean, 2)),
    x = "Injury Event",
    y = "% of Max Velocity"
  ) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# T-test to compare lag_pct_of_max_velocity (the week before) between injury and non injury
t_test_week_prior <- t.test(
  lag1_pct_of_max_velocity ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_week_prior)


# T-test to compare change between current week and last week
t_test_change_lastweek <- t.test(
  change_lastweek ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_change_lastweek)

# T-test to compare change between current week and 2 weeks ago
t_test_change_last2weeks <- t.test(
  change_last2weeks ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_change_last2weeks)

# T-test to compare change between current week and 3 weeks ago
t_test_change_last3weeks <- t.test(
  change_last3weeks ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_change_last3weeks)


# T-test to compare sum of current week, 1, 2, and 3 weeks before
t_test_sum_last3weeks <- t.test(
  sum_last3weeks ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_sum_last3weeks)
```
Mean % of max week before: injury = 86.6, non-injury = 85.9.
Not sig (pvalue = 0.79)

Mean % change week before (current week % - last week %): injury = -0.057, non-injury = -0.49
Not sig (p-value = 0.89)

Mean % change of last 2 weeks (current - 2 weeks ago): injury = -2.68, non-injury = -0.65
Not sig, p-value = 0.44

Mean % change of last 3 weeks (current - 3 weeks ago): injury = -0.6, non-injury = -0.8.
Not sig, p-value = 0.95

```{r}
# Look into the last two weeks

# Drop NAs
lag_2_injury <- injury_week_prior %>%
  drop_na(lag2_pct_of_max_velocity)
lag_2_non_injury <- non_injury_week_prior %>%
  drop_na(lag2_pct_of_max_velocity)

# Calculate means
mean_lag2_injury <- mean(lag_2_injury$lag2_pct_of_max_velocity)
mean_lag2_non_injury <- mean(lag_2_non_injury$lag2_pct_of_max_velocity)
mean_lag2_injury
mean_lag2_non_injury

# Two weeks before:
# T-test to compare lag2_pct_of_max_velocity (2 weeks before) between injury and non injury
t_test_2week_prior <- t.test(
  lag2_pct_of_max_velocity ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_2week_prior)

# Change of last two weeks (lag1 - lag2)
t_test_change_weeks1_2 <- t.test(
  change_weeks1_2 ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_change_weeks1_2)

# Sum of weeks 1 and 2
t_test_sum_weeks1_2 <- t.test(
  sum_weeks1_2 ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_sum_weeks1_2)


# 3 weeks before
# T-test to compare lag3_pct_of_max_velocity (3 weeks before) between injury and non injury
t_test_3week_prior <- t.test(
  lag3_pct_of_max_velocity ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_3week_prior)

# Change between 1 weeks before and 3 weeks before
t_test_change_weeks1_3 <- t.test(
  change_weeks1_3 ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_change_weeks1_3)

# Sum of 1, 2, and 3 weeks before injury
t_test_sum_weeks1_2_3 <- t.test(
  sum_weeks1_2_3 ~ injury, 
  data = week_prior,
  var.equal = FALSE)
print(t_test_sum_weeks1_2_3)
```
2 weeks before injury:
Means of % of max: injury = 88.7, non-injury = 85.8
Not a significant difference in means, p-value, 0.1833 > 0.05.

Means of change: injury = -2.34, non-injury = 0.108
Not significant (p-value = 0.47)

Mean of sum of weeks 1 and 2: injury = 175.14, non-injury = 171.72
Not significant, p-value = 0.333


3 weeks before injury:
Means of % of max: injury = 86.7, non-injury = 85.9
Not a significant difference in means, high p-value, 0.7

Mean sum of 1, 2, and 3 weeks before injury: injury = 261.8, non-injury = 257.3
Not sig, p-value = 0.36

Mean change between 1 and 3 weeks before: injury = -0.26, non-injury = -0.27
Not sig, p-val = 0.99

```{r}
model <- glm(injury ~ change_lastweek + change_last2weeks,
             data = week_prior, family = "binomial")
summary(model)
```
There is no clear evidence that % of max velocity in the current or prior weeks (or their changes/sums) differs between injury and non-injury weeks, based on t-tests of mean differences.

##### Comparing the number of >90% efforts with injury

```{r}
# Convert 90 percent max to logical
# Instead of Yes/No it is True/False
catapult_weekly <- Catapult_Session_clean %>%
  mutate(
    Date = as.Date(Date),
    week = floor_date(Date, unit = "week"),
    Hit90 = Hit.90.Percent.Max == "Yes"  # Convert to logical
  ) %>%
  distinct(anon_id, Date, .keep_all = TRUE)


# Get all combinations of player and week
all_combinations <- catapult_weekly %>%
  distinct(anon_id, week)

# Count weekly >90% sprint hits
weekly_hits <- catapult_weekly %>%
  group_by(anon_id, week) %>%
  summarise(
    count_90pct = sum(Hit90, na.rm = TRUE),
    .groups = "drop"
  )

# Join with all combinations to include zero counts
weekly_90pct <- all_combinations %>%
  left_join(weekly_hits, by = c("anon_id", "week")) %>%
  mutate(count_90pct = replace_na(count_90pct, 0))

distrubution <- weekly_90pct %>%
  count(count_90pct) %>%
  arrange(desc(n))  # Optional: sort from most to least common
```

```{r}
# Create injury weeks
injury_weeks <- Incident_Report_clean %>%
  mutate(
    week = floor_date(as.Date(Date.of.Injury), unit = "week")
  ) %>%
  filter(Date.of.Injury >= as.Date("2024-06-30") & Date.of.Injury <= as.Date("2025-07-01")) %>%
  select(anon_id, week) %>%
  distinct() %>%
  mutate(injury = 1)

# Merge with injury data to have column that indicates injury week
weekly_90pct_injuries <- weekly_90pct %>%
  left_join(injury_weeks, by = c("anon_id", "week")) %>%
  mutate(injury = replace_na(injury, 0))

# Calculate lagged >90% effort counts
weekly_90pct_injuries <- weekly_90pct_injuries %>%
  arrange(anon_id, week) %>%
  group_by(anon_id) %>%
  mutate(
    lag1_90pct_count = lag(count_90pct, 1),
    lag2_90pct_count = lag(count_90pct, 2),
    lag3_90pct_count = lag(count_90pct, 3),
    
    change_lastweek = count_90pct - lag1_90pct_count,
    change_last2weeks = count_90pct - lag2_90pct_count,
    change_last3weeks = count_90pct - lag3_90pct_count,
    
    sum_last2weeks = count_90pct + lag1_90pct_count,
    sum_last3weeks = count_90pct + lag1_90pct_count + lag2_90pct_count,
    
    avg_lastweek = (count_90pct + lag1_90pct_count) / 2,
    avg_last2weeks = (count_90pct + lag1_90pct_count + lag2_90pct_count) / 3,
    avg_last3weeks = (count_90pct + lag1_90pct_count + lag2_90pct_count + lag3_90pct_count) / 4
  ) %>%
  ungroup()
```

```{r}
# Bar chart of sprint counts the week of an injury

# Only injuries
injury_summary <- weekly_90pct_injuries %>%
  group_by(count_90pct) %>%
  summarise(
    total_injuries = sum(injury),
    total_weeks = n()
  )

ggplot(injury_summary, aes(x = factor(count_90pct), y = total_injuries)) +
  geom_col(fill = "#CFB87C") +
  labs(
    x = "Weekly >90% Sprint Count",
    y = "Total Injuries",
    title = "Total Injury Weeks by Weekly Sprint Count"
  ) +
  theme_classic()

```

```{r}
# Injury rate table for current week counts
injury_rate_table <- weekly_90pct_injuries %>%
  group_by(count_90pct) %>%                      # Group by sprint count
  summarise(
    total_weeks = n(),                           # Total weeks with this count
    injury_weeks = sum(injury == 1),             # How many had injury that week
    injury_rate = injury_weeks / total_weeks    # Proportion injured
  ) %>%
  arrange(desc(injury_rate))
injury_rate_table

# Table for counts over last few weeks
weekly_90pct_injuries <- weekly_90pct_injuries %>%
  mutate(avg2_group = round(avg_last2weeks, 1))

# Create binned groups: Low (0–1), Moderate (1–2), High (2+)
weekly_90pct_injuries <- weekly_90pct_injuries %>%
  mutate(load_group = case_when(
    avg_last2weeks < 1 ~ "Low (<1)",
    avg_last2weeks >= 1 & avg_last2weeks < 2 ~ "Moderate(1-2)",
    avg_last2weeks >= 2 ~ "High (2+)"
  ))

# Create a table of counts and injury rates by group
injury_rate_by_group <- weekly_90pct_injuries %>%
  group_by(load_group) %>%
  summarise(
    total_weeks = n(),
    injury_weeks = sum(injury == 1),
    injury_rate = injury_weeks / total_weeks
  ) %>%
  arrange(load_group)  # optional: order Low, Moderate, High
injury_rate_by_group
```
Current week counts:
Injuries increase slightly from 0-3 counts with 3 having the highest injury rate of 1.163%. 4 and 5 counts have no injuries but a low sample size.

Counts over last few weeks (Grouped):
High counts had no injuries
Moderate counts had the highest injury rate (0.96%)
Low counts had a injury rate of 0.65%

Injury rates increased from low counts (<1) injury rate of 0.65% to moderate counts (1-2) injury rate of 0.96% then dropped to 0% for high counts (2+). However, high counts have a small sample size (143), so the rate may be unstable.

```{r}
# Create a contingency table manually
injury_table <- matrix(c(
  11, 1699,   # Low: injured, not injured
  6, 627,     # Moderate: injured, not injured
  0, 143      # High: injured, not injured
), nrow = 3, byrow = TRUE)

# Add row and column names for clarity
rownames(injury_table) <- c("Low", "Moderate", "High")
colnames(injury_table) <- c("Injured", "Not_Injured")

# Run Fisher's Exact Test
fisher_result <- fisher.test(injury_table)

# View the result
print(fisher_result)
```
Our p-value of 0.56 means that there is no statically significance association between our sprint load groups and injury. 
Injury events are pretty rare overall in our dataset, making it hard to detect subtle differences.

```{r}
# T-tests:

# Current week
t.test(count_90pct ~ injury, data = weekly_90pct_injuries, var.equal = FALSE)

# Week before
t.test(lag1_90pct_count ~ injury, data = weekly_90pct_injuries, var.equal = FALSE)

# Change last week to this week
t.test(change_lastweek ~ injury, data = weekly_90pct_injuries, var.equal = FALSE)

# Change last two weeks
t.test(change_last2weeks ~ injury, data = weekly_90pct_injuries, var.equal = FALSE)

# Sum over last 2 weeks
t.test(sum_last2weeks ~ injury, data = weekly_90pct_injuries, var.equal = FALSE)


```

```{r}
weekly_90pct_injuries <- weekly_90pct_injuries %>%
  mutate(
    sprint_exposure_bin = ifelse(count_90pct > 0, "Some", "None")
  )

table_exposure <- table(weekly_90pct_injuries$sprint_exposure_bin, weekly_90pct_injuries$injury)

# Fisher's Exact Test
fisher.test(table_exposure)
```
```{r}
# Create top quartile exposure
cutoff <- quantile(weekly_90pct_injuries$count_90pct, 0.75, na.rm = TRUE)

weekly_90pct_injuries <- weekly_90pct_injuries %>%
  mutate(
    sprint_exposure_group = ifelse(count_90pct >= cutoff, "High", "Low")
  )

table_quartile <- table(weekly_90pct_injuries$sprint_exposure_group, weekly_90pct_injuries$injury)

fisher.test(table_quartile)
```


```{r}
glm(injury ~ count_90pct, data = weekly_90pct_injuries, family = "binomial")

glm(injury ~ lag1_90pct_count, data = weekly_90pct_injuries, family = "binomial")

change <- glm(injury ~ change_lastweek, data = weekly_90pct_injuries, family = "binomial")
summary(change)
glm(injury ~ change_last2weeks, data = weekly_90pct_injuries, family = "binomial")


sum <- glm(injury ~ sum_last3weeks, data = weekly_90pct_injuries, family = "binomial")
summary(sum)
```

```{r}
multi_model <- glm(
  injury ~ count_90pct + sum_last2weeks,
  data = weekly_90pct_injuries,
  family = "binomial"
)

summary(multi_model)
```


```{r}
ggplot(weekly_90pct_injuries, aes(x = change_lastweek, y = injury)) +
  geom_jitter(height = 0.05, alpha = 0.3, color = "blue") +  # Jitter to spread points vertically
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = TRUE, color = "red") +  # Logistic regression curve
  labs(
    title = "Probability of Injury vs Change in >90% Sprint Counts (Last Week)",
    x = "Change in >90% Sprint Counts (Current Week - Previous Week)",
    y = "Injury (0 = No, 1 = Yes)"
  ) +
  theme_minimal()
```

No t-tests or models revealed any insights. 

Separate sprint counts into groups


```{r}
# Create groups for number of sprint counts

summary(weekly_90pct_injuries$count_90pct)

weekly_90pct_injuries <- weekly_90pct_injuries %>%
  mutate(
    sprint_group = case_when(
      count_90pct == 0          ~ "Low",
      count_90pct >= 1 & count_90pct <= 7  ~ "Moderate",
      count_90pct >= 8          ~ "High",
      TRUE                      ~ NA_character_
    )
  )

# check counts
table(weekly_90pct_injuries$sprint_group, useNA = "ifany")
```

```{r}
group_model <- glm(
  injury ~ sprint_group,
  data = weekly_90pct_injuries,
  family = "binomial"
)

summary(group_model)
```

```{r}
weekly_90pct_injuries %>%
  group_by(sprint_group) %>%
  summarise(
    injury_rate = mean(injury, na.rm = TRUE),
    n = n()
  ) %>%
  ggplot(aes(x = sprint_group, y = injury_rate, fill = sprint_group)) +
  geom_col() +
  geom_text(aes(label = scales::percent(injury_rate, accuracy = 0.1)), vjust = -0.5) +
  labs(title = "Injury Rate by Sprint Group",
       x = "Sprint Group",
       y = "Injury Rate") +
  theme_minimal()
```


```{r removing unnecessary objects for running imbalance analysis}
#removing extra data
remove(band_long, bigs, clean_anons, combo, cor_data, cor_matrix, daily_90_counts,
       full_grid, hit_90_counts, ID_11, Incident_dates, injured_data, injuries_and_running,
       injury_by_group, injury_weeks, max_velocities, model_all_bands, model_big,
       model_bigs, model_combo, model_skill, player_counts_long, player_data,
       player_positions, plot_data, plots_by_position, position_averages,
       position_averages_with_team, pre_injury_weeks, QBs, relative_bands,
       relative_bands_long, skill, sprint_counts, sprint_exposure_big,
       sprint_exposure_combo, sprint_exposure_skill, sprint_injury_table, V8, 
       weekly_90_counts, weekly_band_effort_by_group, weekly_effort, weekly_effort_long,
       weekly_effort_wide, weekly_max_pct, weekly_max_velocity, weekly_sprint_counts,
       weekly_sprint_counts_lagged, weekly_sprint_exposure, weekly_velocity_efforts)

#removing extra values and functions
remove(all_athletes, all_weeks, band_levels, BIG, COMBO, SKILL, injured_ids,
       injury_week_nums, overall_avg, player_id, positions, Positions, qb_avg, team_avg,
       plot_hit_90_by_position)
```


## Maximum Velocity Trends over Time
```{r}
catapult_ids <- unique(Catapult_Session_clean$anon_id)

Catapult_Session_clean <- Catapult_Session_clean %>%
  group_by(anon_id) %>%
  mutate(week = floor_date(Date, unit="week")) %>%
  ungroup() %>%
  group_by(anon_id, week) %>%
  mutate(Week.Max.Velocity = mean(na.omit(Session.Max.Velocity)))

kendalls <- rep(NA, 104)
negative_trend <- "0"

for(i in 1:104){
  
  speeds <- unique(Catapult_Session_clean[Catapult_Session_clean$anon_id==catapult_ids[i],]$Week.Max.Velocity)
  weeks <- rev(1:length(speeds))
  
  kend <- cor(weeks, speeds, method="kendall")
  
  if(length(speeds)>5){
  kendalls[i] = kend
  
    if(kend <= -0.5){
      negative_trend <- c(negative_trend, catapult_ids[i])
    }
  
  p <- ggplot(filter(Catapult_Session_clean, anon_id == catapult_ids[i]), aes(week,
                                                            Week.Max.Velocity)) +
  geom_point(color=ifelse(kend <= -0.5, "red", "black")) +
  geom_line(color=ifelse(kend <= -0.5, "red", "black")) +
  labs(title = "Average Top Running Speed per Week", subtitle=kend) +
  ylim(0,25)
       
       
  print(p)
  
  
  }
  
}
```
```{r}
hist(kendalls)
abline(v=-0.5)
abline(v=0.5) 
abline(v=median(na.omit(kendalls)))
```
Based on the Kendall Correlations calculated from the average maximum velocity per week for each player we can see that the distributions of correlations shows that most players tend to have a weak Kendall Correlation coefficient. This suggests that player may tend to see a decrease in maximum velocity per week throughout their time at CU. For most players with a negative coefficient though, it is considered really weak. The players with a strong negative correlation coefficient are ID 30, ID 178, ID 220, and ID 65. These are the ones that have almost a definitive negative trend in their maximum running speeds. These players are the only ones that we can say for certain have seen a decrease in their top running speed. 

```{r}
data_130 <- Catapult_Session_clean %>%
  filter(anon_id == "ID_130")
data_178 <- Catapult_Session_clean %>%
  filter(anon_id == "ID_178")
data_220 <- Catapult_Session_clean %>%
  filter(anon_id == "ID_220")
data_65 <- Catapult_Session_clean %>%
  filter(anon_id == "ID_65")

model_130 <- lm(Week.Max.Velocity ~ week, data=data_130)
summary(model_130)
model_178 <- lm(Week.Max.Velocity ~ week, data=data_178)
summary(model_178)
model_220 <- lm(Week.Max.Velocity ~ week, data=data_220)
summary(model_220)
model_65 <- lm(Week.Max.Velocity ~ week, data=data_65)
summary(model_65)
```
Looking at the slope coefficients for players that had the lowest correlation coefficients we can see that all of them had a relatively small slope value. All of them being lower than 0.04 in absolute value. This suggests that while they had a detectable negative trend throughout their time at CU, none of them had any sharp decreases. 


# Section 2: Running Imbalance

## What is the variation at the team level and at each individual athlete level?

  Looking at team data as a whole, since January 1, 2024 there is absolute no deviance from 0. That means that since January 1, 2024, the team has had the same average running imbalance of 0. This makes sense given that the team is so large and that imbalances can go from -100% to 100%. This suggests that throughout this time, at no point was there a team sway to one side. There also weren't any points since January 1, 2024 that the team had any large spikes in average absolute value of running imbalance. This suggests that at no point throughout the season were there larger spikes than normal in running imbalance. 
  Each player tends to have a very unique trend in their running imbalance. Looking at how the team varies but also at how each player varies throughout the season, it's hard to make out any pattern that's applicable to most people. The variance of running imbalance varies greatly between each player. Instead we looked at the variances between players who were injured and those who were not. Based on three different bootstrapped findings, we can see that the variances between players who were injured and those who were not were statistically significant.
  
  For the first bootstrap, we compared the variance of the pooled groups meaning that the variance in running imbalance for players who were injured and those who were not were compared. This resulted in a 90% confidence interval which suggested that the difference in variance between the two groups is between 0.30 and 3.45. This suggests that when looking at the variance of the two groups separately but all the players are pooled together, the variances will most likely be different by factor between 0.30 and 3.45 and the variance for the injured pool will be greater than that of the uninjured pool.
  For the second bootstrap, each player's variance was taken individually. This unpooled approach was taken to see if an individual player's variance in running imbalance could potentially be related to HSI risk. The bootstrap algorithm in this case took the averaged variances of the bootstrapped sample for each group and compared them. This bootstrap produced a 90% confidence interval for the difference in average variance between the two groups is 0.79 to 1.32. These results suggest that players who sustained a hamstring injury since January 1, 2024 had, on average, a greater variance in their running imbalance by about 1.06. This suggests that there is a relationship between variance in running imbalance and HSI risk. This found increase in variability will be used to address the following questions.
  For the third bootstrap, we wanted to see if there was a difference in the average mean absolute value in running imbalance between players who were and weren't injured. The bootstrapping algorithm for this test calculated the average absolute distance value or each running imbalance measurement and found the average for each sample. This test found that at the 90% significance level, injured players had an average running imbalance absolute value between 0.06 and 0.32 greater than their uninjured counterparts. These values though, when we consider that the range of running imbalance goes from 0 to 100 is small and may be hard to detect when out in the field. 
  
  We also looked at the relationship between running imbalance and higher level position. From this analysis we found that there doesn't seem to be a super strong relationship between the three categories and average running imbalance variance. The bootstrap revealed that there are potentially significant differences between those who are Bigs and Combos. But, those who are Skills weren't able to differentiate themselves between the two groups. 
  Along with this, we looked at the average absolute value in running imbalance for the three groups. This analysis told us that while Combos and Bigs tended to have the same average absolute value running imbalance, Skills had a significantly higher average absolute running imbalance value. 
  We can see from the very last chart in this analysis that Skills make up the most of those with hamstring injuries followed closely by Combos and Bigs making up around half of the amount of Skills. This is interesting considering that the amounts of Bigs, Skills, and Combos within the Historical Running data set are all roughly the same. 

### Team Analysis
```{r Looking at team and player variances of running imbalance}
#team variation
Historical_Running_clean %>%
  summarize(Team_Variation = var(Running.Imbalance))

#individual player variation
Historical_Running_clean %>%
  group_by(anon_id) %>%
  summarize(Player_Variation = var(na.omit(Running.Imbalance))) %>%
  ungroup() 

#average variance in running imbalance across all players
Historical_Running_clean %>%
  group_by(anon_id) %>%
  mutate(Player.var = var(na.omit(Running.Imbalance))) %>%
  ungroup() %>%
  summarize(Average_Player_Variance = mean(na.omit(Player.var)))

#making variance and average absolute value for each date to see trends
Historical_Running_clean <- Historical_Running_clean %>%
  group_by(Date) %>%
  mutate(Date.Variance = var(na.omit(Running.Imbalance)),
         Date.Avg.Abs.Value = mean(abs(na.omit(Running.Imbalance)))) %>%
  ungroup()
```


```{r Running imbalance measurements for whole team since January 1, 2024}
#calculating mean and variance for team data
team_mean <- mean(Historical_Running_clean$Running.Imbalance)
team_sd <- sd(Historical_Running_clean$Running.Imbalance)

#making scatter plot of team running imbalance data throughout season
ggplot(Historical_Running_clean, aes(Date, Running.Imbalance)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = team_mean, color = "#CFB87C") +
  geom_hline(yintercept = team_mean + team_sd) +
  geom_hline(yintercept = team_mean - team_sd) +
  geom_hline(yintercept = team_mean + (2*team_sd), color = "#A2A4A3") +
  geom_hline(yintercept = team_mean - (2*team_sd), color = "#A2A4A3") +
  geom_smooth(method = "lm", se = TRUE, color = "#CFB87C") +
  labs(title = "Team Running Imbalance Since January 1, 2024", y="Running Imbalance (%)",
       subtitle = "\u03BC = 0.08623412, \u03C3^2 = 14.94215")

#making scatter plot of team running imbalance data throughout season
ggplot(Historical_Running_clean, aes(Date, Running.Imbalance)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = team_mean, color = "#CFB87C") +
  geom_smooth(method = "lm", se = TRUE, color = "#CFB87C") +
  geom_line(aes(x=Date, y=Date.Avg.Abs.Value), color = "#CFB87C") +
  geom_line(aes(x=Date, y=-Date.Avg.Abs.Value), color = "#CFB87C") +
  labs(title = "Team Running Imbalance Since January 1, 2024", y="Running Imbalance (%)",
       subtitle = "\u03BC = 0.08623412, \u03C3^2 = 14.94215")

#making histogram of team running imbalance data
ggplot(Historical_Running_clean, aes(Running.Imbalance)) +
  geom_histogram() +
  labs(title = "Team Running Imbalance Since January 1, 2024", x="Running Imbalance")
```


### Injured Analysis
```{r Looking at distributions for injured and uninjured separately}
#making histogram for running imbalance of all injured athletes
ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id %in% injured_IDs,], aes(Running.Imbalance)) +
  geom_histogram(fill = "#CFB87C", alpha = 0.75) +
  #adding in 95% confidence interval
  geom_vline(xintercept = quantile(Historical_Running_clean[Historical_Running_clean$anon_id %in% injured_IDs,]$Running.Imbalance, 0.025), color = "#CFB87C") +
  geom_vline(xintercept = quantile(Historical_Running_clean[Historical_Running_clean$anon_id %in% injured_IDs,]$Running.Imbalance, 0.975), color = "#CFB87C") +
  xlim(-21,21) +
  labs(title = "Running Imbalance for Players with HSI since January 1, 2024")

#making histogram for running imbalance of all uninjured athletes
ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id %in% uninjured_IDs,], aes(Running.Imbalance)) +
  geom_histogram(fill = "black", alpha = 0.75) +
  #adding in 95% confidence interval
  geom_vline(xintercept = quantile(Historical_Running_clean[Historical_Running_clean$anon_id %in% uninjured_IDs,]$Running.Imbalance, 0.025)) +
  geom_vline(xintercept = quantile(Historical_Running_clean[Historical_Running_clean$anon_id %in% uninjured_IDs,]$Running.Imbalance, 0.975)) +
  xlim(-21,21) +
  labs(title = "Running Imbalance for Players without HSI since January 1, 2024")

#Plotting injured and uninjured histograms over top one another
ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id %in% uninjured_IDs,], aes(Running.Imbalance)) +
  geom_histogram(alpha = 0.75) +
  #adding in 95% CI for uninjured players
  geom_vline(xintercept = quantile(Historical_Running_clean[Historical_Running_clean$anon_id %in% uninjured_IDs,]$Running.Imbalance, 0.05)) +
  geom_vline(xintercept = quantile(Historical_Running_clean[Historical_Running_clean$anon_id %in% uninjured_IDs,]$Running.Imbalance, 0.95)) +
  geom_histogram(data = Historical_Running_clean[Historical_Running_clean$anon_id %in% injured_IDs,], aes(Running.Imbalance), fill = "#CFB87C", alpha = 0.75) +
  #adding in 95% CI for injured players
  geom_vline(xintercept = quantile(Historical_Running_clean[Historical_Running_clean$anon_id %in% injured_IDs,]$Running.Imbalance, 0.05), color = "#CFB87C") +
  geom_vline(xintercept = quantile(Historical_Running_clean[Historical_Running_clean$anon_id %in% injured_IDs,]$Running.Imbalance, 0.95), color = "#CFB87C") +
  xlim(-21,21) +
  labs(title = "Running Imbalance for Players with and without HSI since January 1, 2024")
```


```{r looking at trends for injured and uninjured players since 1-1-2024}
#making scatter plot of running imbalance data for injured players
ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id %in% injured_IDs,], aes(Date, Running.Imbalance)) + 
  geom_point(alpha = 0.3) +
  ylim(-21,21) +
  labs(title = "Running Imbalance for Players with HSI since January 1, 2024")

#making scatter plot of running imbalance for uninjured players
ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id %in% uninjured_IDs,], aes(Date, Running.Imbalance)) + 
  geom_point(alpha = 0.3) +
  ylim(-21,21) +
  labs(title = "Running Imbalance for Players without HSI since January 1, 2024")
```


#### Bootstrapping Differences between Injured and Uninjured Athletes
```{r Separating injured and uninjured into two different data sets}
#Splitting up the data sets and calculating player variance and measurement absolute value
injured_data <- Historical_Running_clean[Historical_Running_clean$anon_id %in% injured_IDs,] %>%
  mutate(Player.Absolute.Dist = abs(Running.Imbalance)) %>%
  group_by(anon_id) %>%
  mutate(Player.Variance = var(Running.Imbalance)) %>%
  ungroup()

uninjured_data <- Historical_Running_clean[Historical_Running_clean$anon_id %in% uninjured_IDs,] %>%
  mutate(Player.Absolute.Dist = abs(Running.Imbalance)) %>%
  group_by(anon_id) %>%
  mutate(Player.Variance = var(Running.Imbalance)) %>%
  ungroup()
```


```{r Boostrapping to look at variances of different groups, pooled}
#making a data frame to hold all of the within group variances
group_variances <- data.frame(injured_var = rep(NA,5000),
                uninjured_var = rep(NA,5000),
                diff_in_var = rep(NA, 5000))

#bootstrap for variance, 5000 iterations
for(i in 1:5000){
  #random seed
  set.seed(i) 
  
  #taking samples from each of the data sets, same number of rows, replacement true
  injured_sample <- sample_n(injured_data, replace = TRUE, size = 1672)
  uninjured_sample <- sample_n(uninjured_data, replace=TRUE, size = 2391)
  
  #storing the calculated variances in data frame
  group_variances[i,1] = var(injured_sample$Running.Imbalance)
  group_variances[i,2] = var(uninjured_sample$Running.Imbalance)
  group_variances[i,3] = group_variances[i,1] - group_variances[i,2]
}
```


```{r Plotting results from pooled boostrapped variances}
ggplot(data=group_variances, aes(diff_in_var)) +
  geom_histogram() +
  geom_vline(xintercept = quantile(group_variances$diff_in_var, 0.05), color= "#CFB87C") +
  geom_vline(xintercept = quantile(group_variances$diff_in_var, 0.95), color= "#CFB87C") +
  labs(x="Difference in Variance")

ggplot(data=group_variances) +
  geom_histogram(aes(injured_var), alpha = 0.75, fill ="#CFB87C") +
  geom_histogram(aes(uninjured_var), alpha = 0.75) +
  labs(x="Variance")
```


```{r Bootstrapping to look at average player variances}
#making a data frame to hold all of the average player variances between groups
mean_player_variances <- data.frame(injured_var = rep(NA,5000),
                uninjured_var = rep(NA,5000),
                diff_in_var = rep(NA, 5000))

for(i in 1:5000){
  #random seed
  set.seed(i) 
  
  #taking samples from each of the data sets, same number of rows, replacement true
  injured_sample <- sample_n(injured_data, replace = TRUE, size = 1672)
  uninjured_sample <- sample_n(uninjured_data, replace=TRUE, size = 2391)
  
  #storing the calculated variances in data frame
  mean_player_variances[i,1] = mean(na.omit(injured_sample$Player.Variance))
  mean_player_variances[i,2] = mean(na.omit(uninjured_sample$Player.Variance))
  mean_player_variances[i,3] = mean_player_variances[i,1] - mean_player_variances[i,2]
}
```


```{r Plotting results from averaged bootstrapped player variances}
ggplot(data = mean_player_variances, aes(diff_in_var)) +
  geom_histogram() +
  geom_vline(xintercept = quantile(mean_player_variances$diff_in_var, 0.05), color= "#CFB87C") +
  geom_vline(xintercept = quantile(mean_player_variances$diff_in_var, 0.95), color= "#CFB87C") +
  labs(x="Difference in Average Variance")

ggplot(data=mean_player_variances) +
  geom_histogram(aes(injured_var), alpha = 0.75, fill ="#CFB87C") +
  geom_histogram(aes(uninjured_var), alpha = 0.75) +
  labs(x="Average Variance")
```


```{r Bootstrapping to look at average absolute value running imbalance}
#making a data frame to hold all of the average absolute differences from 0
group_distance <- data.frame(injured_dist = rep(NA,5000),
                uninjured_dist = rep(NA,5000),
                diff_in_dist = rep(NA, 5000))

#bootstrap for variances, 5000 iterations
for(i in 1:5000){
  #random seed
  set.seed(i) 
  
  #taking samples from each of the data sets, same number of rows, replacement true
  injured_sample <- sample_n(injured_data, replace = TRUE, size = 1658)
  uninjured_sample <- sample_n(uninjured_data, replace=TRUE, size = 2405)
  
  #storing the calculated variances in data frame
  group_distance[i,1] = mean(injured_sample$Player.Absolute.Dist)
  group_distance[i,2] = mean(uninjured_sample$Player.Absolute.Dist)
  group_distance[i,3] = group_distance[i,1] - group_distance[i,2]
}
```


```{r Plotting results from averaged boostrapped absolute value running imbalance}
ggplot(data = group_distance, aes(diff_in_dist)) +
  geom_histogram() +
  geom_vline(xintercept = quantile(group_distance$diff_in_dist, 0.05), color= "#CFB87C") +
  geom_vline(xintercept = quantile(group_distance$diff_in_dist, 0.95), color= "#CFB87C") +
  labs(x="Difference in Distance")

ggplot(data = group_distance) +
  geom_histogram(aes(injured_dist), alpha = 0.75, fill ="#CFB87C") +
  geom_histogram(aes(uninjured_dist), alpha = 0.75) +
  labs(x="Average Absolute Value")
```


```{r Removing unnecessary objects from loops}
#removing junk that came from the loops
remove(i,team_mean, team_sd, injured_sample, uninjured_sample, group_variances, injured_data, uninjured_data, mean_player_variances, group_distance)
```


### Position Analysis
```{r sorting player into general positions}
#making lists to sort position into larger categories
COMBO <- c("QB","LB","TE","RB", "ILB")
BIG <- c("OL", "DL", "DE", "DT")
SKILL <- c("WR", "DB", "CB", "SAF")
Positions <- c("COMBO", "BIG", "SKILL")

#giving positions to incident report
Incident_Report_clean <- Incident_Report_clean %>%
  mutate(Specific.Position = Position,
         Position = case_when(Specific.Position %in% COMBO ~ "COMBO",
                               Specific.Position %in% BIG ~ "BIG",
                               Specific.Position %in% SKILL ~ "SKILL"))

#giving positions to catapult session
Catapult_Session_clean <- Catapult_Session_clean %>%
  mutate(Specific.Position = Primary.Position,
         Position = case_when(Primary.Position %in% COMBO ~ "COMBO",
                               Primary.Position %in% BIG ~ "BIG",
                               Primary.Position %in% SKILL ~ "SKILL"))

#only taking IDs and position names and categories
incident_info <- Incident_Report_clean[,c("anon_id", "Position", "Specific.Position")]
catapult_info <- Catapult_Session_clean[,c("anon_id", "Position", "Specific.Position")]

#comprehensive list of IDs, their position, and category
info <- distinct(rbind(incident_info, catapult_info))

#add this only historical running
Historical_Running_clean <- left_join(Historical_Running_clean, info, by="anon_id",
                                      relationship="many-to-many") %>%
  #calculating each player's variance in running imbalance
  group_by(anon_id) %>%
  mutate(Player.Variance = var(Running.Imbalance)) %>%
  ungroup()
```


```{r Looking at Running Imbalance }
for(i in 1:3){
  p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$Position==Positions[i],],aes(Running.Imbalance)) +
    geom_histogram() +
    labs(subtitle=Positions[i])
  
  print(p)
}
```

```{r}
Player_Summary_Stats <- distinct(Historical_Running_clean[,c("anon_id", "Position",
                                                 "Specific.Position", 
                                                 "Player.Variance")])
```


```{r}
for(i in 1:3){
  p <- ggplot(data=Player_Summary_Stats[Player_Summary_Stats$Position==Positions[i],],
              aes(Player.Variance)) +
    geom_histogram() +
    labs(subtitle=Positions[i])
  
  print(p)
}
```


#### Bootstrapping Different Positions
```{r}
#splitting up data set into the different categories
COMBOS <- Player_Summary_Stats %>%
  filter(Position == "COMBO") %>%
  na.omit()

SKILLS <- Player_Summary_Stats %>%
  filter(Position == "SKILL") %>%
  na.omit()

BIGS <- Player_Summary_Stats %>%
  filter(Position == "BIG") %>%
  na.omit()

group_avg_variance <- data.frame(COMBO_var = rep(NA, 5000),
                                 SKILL_var = rep(NA, 5000),
                                 BIG_var = rep(NA, 5000))
```


```{r}
for(i in 1:5000){
  set.seed(i)
  combo_sample <- sample_n(COMBOS, size=20, replace=TRUE)
  skill_sample <- sample_n(SKILLS, size=22, replace=TRUE)
  big_sample <- sample_n(BIGS, size=24, replace=TRUE)
  
  group_avg_variance[i,1] <- mean(na.omit(combo_sample$Player.Variance))
  group_avg_variance[i,2] <- mean(na.omit(skill_sample$Player.Variance))
  group_avg_variance[i,3] <- mean(na.omit(big_sample$Player.Variance))
}
```


```{r}
ggplot(data=group_avg_variance, aes(COMBO_var)) +
  geom_histogram() +
  geom_vline(xintercept = quantile(group_avg_variance$COMBO_var, 0.05)) +
  geom_vline(xintercept = quantile(group_avg_variance$COMBO_var, 0.95))

ggplot(data=group_avg_variance, aes(SKILL_var)) +
  geom_histogram() +
  geom_vline(xintercept = quantile(group_avg_variance$SKILL_var, 0.05)) +
  geom_vline(xintercept = quantile(group_avg_variance$SKILL_var, 0.95))

ggplot(data=group_avg_variance, aes(BIG_var)) +
  geom_histogram() +
  geom_vline(xintercept = quantile(group_avg_variance$BIG_var, 0.05)) +
  geom_vline(xintercept = quantile(group_avg_variance$BIG_var, 0.95))

ggplot(data=group_avg_variance) +
  geom_histogram(aes(COMBO_var), alpha=0.5, fill="red") +
  geom_histogram(aes(SKILL_var), alpha=0.5, fill="blue") +
  geom_histogram(aes(BIG_var), alpha=0.5, fill="yellow")
```
```{r}
var_confints <- data.frame(Category = c("COMBO", "SKILL", "BIG"),
                       Lower_Bound = c(quantile(group_avg_variance$COMBO_var, 0.05), 
                                       quantile(group_avg_variance$SKILL_var, 0.05), 
                                       quantile(group_avg_variance$BIG_var, 0.05)),
                       Median = c(quantile(group_avg_variance$COMBO_var, 0.5),
                                  quantile(group_avg_variance$SKILL_var, 0.5),
                                  quantile(group_avg_variance$BIG_var, 0.5)),
                       Upper_Bound = c(quantile(group_avg_variance$COMBO_var, 0.95),
                                       quantile(group_avg_variance$SKILL_var, 0.95),
                                       quantile(group_avg_variance$BIG_var, 0.95)))
head(var_confints)

ggplot(data=var_confints, aes(x=Category, y=Median, ymin=Lower_Bound, ymax=Upper_Bound)) +
  geom_pointrange() +
  labs(y="Running Imbalance Variance 90% CI")
```
```{r}
Historical_Running_clean <- Historical_Running_clean %>%
  mutate(Abs.Value.Running.Imbalance = abs(Running.Imbalance))

COMBOS <- Historical_Running_clean %>%
  filter(Position == "COMBO")

SKILLS <- Historical_Running_clean %>%
  filter(Position == "SKILL")

BIGS <- Historical_Running_clean %>%
  filter(Position == "BIG")

group_avg_dist <- data.frame(COMBO_dist = rep(NA, 5000),
                             SKILL_dist = rep(NA, 5000),
                             BIG_dist = rep(NA, 5000))
```

```{r}
for(i in 1:5000){
  set.seed(i)
  combo_sample <- sample_n(COMBOS, size=1203, replace=TRUE)
  skill_sample <- sample_n(SKILLS, size=1635, replace=TRUE)
  big_sample <- sample_n(BIGS, size=1224, replace=TRUE)
  
  group_avg_dist[i,1] <- mean(na.omit(combo_sample$Abs.Value.Running.Imbalance))
  group_avg_dist[i,2] <- mean(na.omit(skill_sample$Abs.Value.Running.Imbalance))
  group_avg_dist[i,3] <- mean(na.omit(big_sample$Abs.Value.Running.Imbalance))
}
```


```{r}
ggplot(data=group_avg_dist) +
  geom_histogram(aes(COMBO_dist), alpha=0.5, fill="red") +
  geom_histogram(aes(SKILL_dist), alpha=0.5, fill="blue") +
  geom_histogram(aes(BIG_dist), alpha=0.5, fill="yellow") +
  labs(x="Average Absolute Value Running Imbalance")
```


```{r}
dist_confints <- data.frame(Category = c("COMBO", "SKILL", "BIG"),
                       Lower_Bound = c(quantile(group_avg_dist$COMBO_dist, 0.05), 
                                       quantile(group_avg_dist$SKILL_dist, 0.05), 
                                       quantile(group_avg_dist$BIG_dist, 0.05)),
                       Median = c(quantile(group_avg_dist$COMBO_dist, 0.5),
                                  quantile(group_avg_dist$SKILL_dist, 0.5),
                                  quantile(group_avg_dist$BIG_dist, 0.5)),
                       Upper_Bound = c(quantile(group_avg_dist$COMBO_dist, 0.95),
                                       quantile(group_avg_dist$SKILL_dist, 0.95),
                                       quantile(group_avg_dist$BIG_dist, 0.95)))
head(dist_confints)

ggplot(data=dist_confints, aes(x=Category, y=Median, ymin=Lower_Bound, ymax=Upper_Bound)) +
  geom_pointrange() +
  labs(y="Running Imbalance Absolute Value 90% CI")
```
```{r}
Injury_Incidents <- distinct(Incident_Report_clean[,c("anon_id", "Position", "Date.of.Injury")])

Position_counts <- na.omit(distinct(Historical_Running_clean[,c("anon_id", "Position")]))

ggplot(Injury_Incidents, aes(Position)) +
  geom_bar()

ggplot(Position_counts, aes(Position)) +
  geom_bar()
```

```{r Removing unnecessary objects from environment}
remove(big_sample, BIGS, catapult_info, combo_sample, COMBOS, confints, group_avg_variance,
       incident_info, info, p, Player_Summary_Stats, skill_sample, SKILLS, BIG, COMBO, i,
       Positions, SKILL, dist_confints, group_avg_variance, group_avg_dist, group_distance, 
       group_variances, injured_data, injured_sample, Injury_Incidents, mean_player_variances, 
       Position_counts, var_confints)
```


## What is a meaningful change? What red flags should go off when we see a week-to-week change in running imbalance?

  Based on the analysis below, there doesn't seem to be any major discernible differences in running imbalance before or following an injury. This suggests that there may not be a direct link between HSI risk and running imbalance value directly beforehand. Instead, the trends of many players who were injured seems to have a relatively consistent trend not entirely dependent on time. 
  Looking at summary statistics of running imbalance in the weeks leading up to and following a hamstring injury, there are also no glaring trends. For this analysis, we looked at the mean and variance in running imbalance per week leading up to and after an injury for all of the injured players with running imbalance data. This showed us that there is no clear indicator of HSI risk in running imbalance or any summary statistic of it. Instead it may be more useful to look at each player's total running imbalance and their individual variance. This seems to be more of a useful tool for differentiating between injured and uninjured athletes.

```{r Calculating weeks before and after injury occurance based on date, how many injuries player has}
#getting running imbalances for just injured players
Injured_Historical_Running <- Historical_Running_clean %>%
  filter(anon_id %in% injured_IDs)

#making new column to represent when in time injury would be, negative means before injury and positive means after injury, 0 means date of injury if there's data for that day
Injured_Historical_Running$Weeks.After.Injury <- rep(NA, 1658)
Injured_Historical_Running$Injury.Count <- rep(NA, 1658)

#making new column in incident report for the injury count
Incident_Report_clean$Injury.Count <- rep(NA, 122)

#go through all of the injured players in the data set
for(i in 1:22){
  #get the dates each player was injured
  injury_dates <- unique(Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury)
  
  #go through all of the dates in which the player had an injury
  for(j in 1:length(injury_dates)){
    
    #calculate dates for 1, 2, 3, 4 weeks before and after each injury date
    past_1 <- injury_dates[j]-7
    past_2 <- injury_dates[j]-14
    past_3 <- injury_dates[j]-21
    past_4 <- injury_dates[j]-28
    future_1 <- injury_dates[j]+7
    future_2 <- injury_dates[j]+14
    future_3 <- injury_dates[j]+21
    future_4 <- injury_dates[j]+28
    
    #Calculating how many injuries this is for the player
    injury_count <- as.character((length(injury_dates)) - j + 1)
    
    #compare date of data point for each player to date of injury, store in Weeks.After.Injury column, store injury count
    
    #first week after injury
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date > injury_dates[j] & 
                                 Injured_Historical_Running$Date<=future_1,]$Weeks.After.Injury <- "1"
    
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date > injury_dates[j] & 
                                 Injured_Historical_Running$Date<=future_1,]$Injury.Count <- injury_count
    
    #second week after injury
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date > future_1 & 
                                 Injured_Historical_Running$Date<=future_2,]$Weeks.After.Injury <- "2"
    
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date > future_1 & 
                                 Injured_Historical_Running$Date<=future_2,]$Injury.Count <- injury_count
    
    #third week after injury
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date > future_2 & 
                                 Injured_Historical_Running$Date<=future_3,]$Weeks.After.Injury <- "3"
    
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date > future_2 & 
                                 Injured_Historical_Running$Date<=future_3,]$Injury.Count <- injury_count
    
    #fourth week after injury
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date > future_3 & 
                                 Injured_Historical_Running$Date<=future_4,]$Weeks.After.Injury <- "4"
    
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date > future_3 & 
                                 Injured_Historical_Running$Date<=future_4,]$Injury.Count <- injury_count    
    #week right before injury
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date < injury_dates[j] & 
                                 Injured_Historical_Running$Date>=past_1,]$Weeks.After.Injury <- "-1"
    
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date < injury_dates[j] & 
                                 Injured_Historical_Running$Date>=past_1,]$Injury.Count <- injury_count
    #two weeks before injury
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date < past_1 & 
                                 Injured_Historical_Running$Date>=past_2,]$Weeks.After.Injury <- "-2"
    
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date < past_1 & 
                                 Injured_Historical_Running$Date>=past_2,]$Injury.Count <- injury_count
    
    #three weeks before injury
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date < past_2 & 
                                 Injured_Historical_Running$Date>=past_3,]$Weeks.After.Injury <- "-3"
    
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date < past_2 & 
                                 Injured_Historical_Running$Date>=past_3,]$Injury.Count <- injury_count
        
    #four weeks before injury
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date < past_3 & 
                                 Injured_Historical_Running$Date>=past_4,]$Weeks.After.Injury <- "-4"
    
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date < past_3 & 
                                 Injured_Historical_Running$Date>=past_4,]$Injury.Count <- injury_count
    
    #Date of Injury
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date == injury_dates[j],]$Weeks.After.Injury <- "0"
    
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] &
                                 Injured_Historical_Running$Date == injury_dates[j],]$Injury.Count <- injury_count
    
    
    #adding injury count to indicent report
    Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i] & Incident_Report_clean$Date.of.Injury==injury_dates[j],]$Injury.Count <- injury_count
    
  }
}


#making weeks after injury and injury count into a factor and combining data sets back together
Injured_Historical_Running <- Injured_Historical_Running %>%
  mutate(Weeks.After.Injury = factor(Weeks.After.Injury),
         Injury.Count = factor(Injury.Count))

Historical_Running_clean <- left_join(Historical_Running_clean, Injured_Historical_Running)

#getting rid of junk that was from the loop
remove(future_1, future_2, future_3, future_4, i, injury_count, injury_dates, j, past_1, past_2, past_3, past_4)
remove(Injured_Historical_Running)
```

### Injury Risk
```{r}
for(i in 1:22){
  p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id==injured_IDs[i],], aes(Date, Running.Imbalance)) +
    geom_line(linetype=1) +
    geom_point(aes(color=Weeks.After.Injury)) +
    geom_vline(xintercept = Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury, linetype=2) +
    scale_color_manual(values = c("-4"="green", "-3"="yellow", "-2"="orange", "-1"="red", "0"="black","1"= "purple", "2"="navy", "3"="blue", "4"="skyblue")) +
    theme_minimal() +
    labs(title="Running Imbalance", subtitle = injured_IDs[i])
  
  print(p)
}
```


```{r}
#making summary statistics of running imbalance per week relative to injury
Historical_Running_clean <- Historical_Running_clean %>%
  group_by(anon_id, Injury.Count, Weeks.After.Injury) %>%
  mutate(Weeks.After.Injury.Variability = var(Running.Imbalance),
         Weeks.After.Injury.Mean = mean(abs(Running.Imbalance))) %>%
  ungroup()
```


```{r warning=FALSE}
for(i in 1:22){
  #looking at mean running imbalance per week before and after injury for each injured player
  p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id == injured_IDs[i],], aes(Date, Weeks.After.Injury.Mean, group=Injury.Count)) +
  geom_line() +
  geom_point(aes(color=Weeks.After.Injury)) +
    xlim(min(Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury)-30, max(Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury)+30) +
  geom_vline(xintercept = Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury) +
    labs(title="Average Absolute Distance per Week",injured_IDs[i]) +
    scale_color_manual(values = c("-4"="green", "-3"="yellow", "-2"="orange", "-1"="red", "0"="black","1"= "purple", "2"="navy", "3"="blue", "4"="skyblue"))
  
  print(p)
}

```


```{r}
for(i in 1:22){
  #looking at variance in running imbalance per week before and after injury for each injured player
  p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id == injured_IDs[i],], aes(Date, Weeks.After.Injury.Variability, group=Injury.Count)) +
  geom_line() +
  geom_point(aes(color=Weeks.After.Injury)) +
    xlim(min(Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury)-30, max(Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury)+30) +
  geom_vline(xintercept = Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury) +
    labs(title="Variance in Running Imbalance per Week", subtitle=injured_IDs[i]) +
    scale_color_manual(values = c("-4"="green", "-3"="yellow", "-2"="orange", "-1"="red", "0"="black","1"= "purple", "2"="navy", "3"="blue", "4"="skyblue"))
  
  print(p)
}
```

### Player Trends
```{r Looking at detectable trends in player data}
for(i in 1:71){
  #only plotting if there are over 15 data points for each player
  if(nrow(Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],])>15){
    #calculating how strong of a non linear trend there is using a gam
    df <- summary(gam(Running.Imbalance~s(Days.Since.Start),
              data=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],]))$edf
    #calculating how strong of a linear trend there is using kendall correlation
    Kendall_Cor <- cor(x=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],]$Days.Since.Start, y=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],]$Running.Imbalance, method="kendall")
  
    #if there is a detectable linear relationship in the data
if(abs(Kendall_Cor>0.2) & df<=3){ #linear trend in data
  p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],], aes(Date, Running.Imbalance)) +
    geom_line() +
    geom_point() +
    geom_smooth(color= "red",
                method="lm",
                se=FALSE) +
    labs(title="Running Imbalance Since January 1, 2024 (linear trend)", subtitle=all_IDs[i],) +
    xlim(as.Date("2025-01-01", "%Y-%m-%d"), as.Date("2025-05-01", "%Y-%m-%d"))
  
  print(p)
}
    #if there is a detectable non-linear trend in the data
  if(df > 3){ #non linear trend in data
  p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],], aes(Date, Running.Imbalance)) +
    geom_line() +
    geom_point() +
    geom_smooth(color = "skyblue",
                se=FALSE) +
    labs(title="Running Imbalance Since January 1, 2024 (non-linear trend)", subtitle=all_IDs[i],) +
    xlim(as.Date("2025-01-01", "%Y-%m-%d"), as.Date("2025-05-01", "%Y-%m-%d"))
  
  print(p)
  }
    #if there is no detectable trend in the data
    if(df<=3 & abs(Kendall_Cor)<=0.2){
      p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],], aes(Date, Running.Imbalance)) +
    geom_line() +
    geom_point() +
    labs(title="Running Imbalance Since January 1, 2024 (non-linear trend)", subtitle=all_IDs[i],) +
    xlim(as.Date("2025-01-01", "%Y-%m-%d"), as.Date("2025-05-01", "%Y-%m-%d"))
    }
  }
}

#plotted only from January 1, 2025 to May 1, 2025
```


### Detectable Trend with Injury Risk
```{r}
trends <- data.frame(ID = all_IDs,
                     KC = rep(0, 71))
for(i in 1:71){
  #only plotting if there are over 15 data points for each player
  if(nrow(Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],])>15){
    #calculating how strong of a non linear trend there is using a gam
    df <- summary(gam(Running.Imbalance~s(Days.Since.Start),
              data=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],]))$edf
    #calculating how strong of a linear trend there is using kendall correlation
    Kendall_Cor <- cor(x=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],]$Days.Since.Start, y=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],]$Running.Imbalance, method="kendall")
    
    trends[trends$ID == all_IDs[i],2] = Kendall_Cor
  
    if(all_IDs[i] %in% injured_IDs){
      p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],],
             aes(Date, Running.Imbalance)) +
        geom_point(color="skyblue") +
        geom_line(color="skyblue") +
        labs(subtitle=Kendall_Cor)
    }
    if(!(all_IDs[i] %in% injured_IDs)){
      p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id == all_IDs[i],],
             aes(Date, Running.Imbalance)) +
        geom_point() +
        geom_line() +
        labs(subtitle=Kendall_Cor)
    }
    
    print(p)
  }
}

#plotted only from January 1, 2025 to May 1, 2025
```


```{r}
trends <- trends %>%
  mutate(injured = ifelse(ID %in% injured_IDs,1,0))

ggplot(trends[trends$KC>0 & trends$injured==1,], aes(KC)) +
  geom_histogram()

ggplot(trends[trends$KC>0 & trends$injured==0,], aes(KC)) +
  geom_histogram()
```
```{r}
injured_trends <- trends %>%
  filter(injured==1)

uninjured_trends <- trends %>%
  filter(injured==0)


kendall_cors <- data.frame(injured_avg_KC = rep(NA,5000),
                           uninjured_avg_KC = rep(NA,5000),
                           avg_diff_KC = rep(NA,5000))

for(i in 1:5000){
  set.seed(i)
  injured_samp <- sample_n(injured_trends, size=22, replace=TRUE)
  uninjured_samp <- sample_n(uninjured_trends, size=49, replace=TRUE)
  
  kendall_cors[i,1] <- mean(abs(injured_samp$KC))
  kendall_cors[i,2] <- mean(abs(uninjured_samp$KC))
  kendall_cors[i,3] <- kendall_cors[i,1] - kendall_cors[i,2]
}

```


```{r}
ggplot(data=kendall_cors, aes(avg_diff_KC)) +
  geom_histogram() +
  geom_vline(xintercept = quantile(kendall_cors$avg_diff_KC, 0.05)) +
  geom_vline(xintercept = quantile(kendall_cors$avg_diff_KC, 0.95))

ggplot(data=kendall_cors) +
  geom_histogram(aes(injured_avg_KC), alpha=0.3, fill="red") +
  geom_histogram(aes(uninjured_avg_KC), alpha=0.3)
```


```{r removing unnecessary objects from section}
remove(i, p, df, Kendall_Cor, kendall_cors, trends)
```


## Is running imbalance sensitive enough of a metric to use as a prognosis tool versus a rehab tool?

  Based on the analysis below, we can see that by solely using variance in running imbalance from the time of the injury to the end of the predicted return-to-play range is not a very strong predictor for whether or not it will take longer for a player to recover or not. In this analysis, we used the running imbalance in the time frame starting with the injury date to the end of the prognosis time frame. With these specific running imbalance values, we calculated the variance in running imbalance and whether or not the athlete returned to play within the predicted time frame or not. 
  This analysis found that when using the variance in these time frames as the only predictor in a logistic regression model, the slope coefficient associated with the variance was statistically significant at the $\alpha = 0.01$ significance level. With that though, the cross validated accuracy of the model was only around 0.6 suggesting that it wasn't super strong in practice.
  In order to understand the impact that variance in running imbalance had on whether or not a player returned in the predicted time frame or not, we performed a bootstrap. We separated the observations in which players did and did not return in the predicted time frame into two different data sets. We then sampled from each of these two data sets and calculated the average variance for each sample. This was repeated 5000 times. This gave us an estimate of the average variance in running imbalance for players who returned within the predicted time frame and those who did not.
  This bootstrap revealed that players who did not return within the predicted time frame had a variance greater by roughly 1.2 during their time of recovery than those who returned on time. This tells us that while variance in running imbalance is not directly strong enough to predict whether or not an athlete will return within the predicted time frame, it can be used to supplement prognosis or make adjustments to the prognosis during the time of recovery of a HSI. 

```{r}
#Calculating date back to play in incident report data set
Incident_Report_clean <- Incident_Report_clean %>%
  filter(!is.na(Injury.Prognosis))%>%
  #calculating how long predicted time loss is based on prognosis
         #beginning of predicted range of return
  mutate(Expected.Start.Return = as.Date(ifelse(Injury.Prognosis=="No Expected Time Loss",
                                        Date.of.Injury,
                                        ifelse(Injury.Prognosis=="Less than 1 Week",
                                               Date.of.Injury,
                                               ifelse(Injury.Prognosis=="1-4 Weeks",
                                                      Date.of.Injury+days(7),
                                                      Date.of.Injury+days(28))))),
         #end of predicted range of return
         Expected.End.Return = as.Date(ifelse(Injury.Prognosis=="No Expected Time Loss",
                                        Date.of.Injury,
                                        ifelse(Injury.Prognosis=="Less than 1 Week",
                                               Date.of.Injury+days(7),
                                               ifelse(Injury.Prognosis=="1-4 Weeks",
                                                      Date.of.Injury+days(28),
                                                      Date.of.Injury+days(56)))))) %>%
  group_by(anon_id, Date.of.Injury) %>%
  #calculating actual date cleared to return
  mutate(Actual.Return = Date.of.Injury+days(sum(na.omit(Days.in.Status)))) %>%
  ungroup()
```


```{r Looking at if return to play was in predicted range for each player}
for(i in 1:22){
  #looking at mean running imbalance per week before and after injury for each injured player
  p <- ggplot(data=Historical_Running_clean[Historical_Running_clean$anon_id == injured_IDs[i],], aes(Date, Running.Imbalance)) +
  geom_line(linewidth=0.1) +
  geom_point() +
    #Marking when injury occurred with red line
  geom_vline(xintercept=Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury, color="red") +
    #Marking actual return date with solid green line
  geom_vline(xintercept=Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Actual.Return, color="green", linetype=1) +
  #Marking beginning of predicted return to play range with purple dotted line
  geom_vline(xintercept=Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Expected.Start.Return, color="purple", linetype=3) +
    #Marking end of predicted return to play range with purple dotted line
  geom_vline(xintercept=Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Expected.End.Return, color="purple", linetype=3) +
    labs(title=injured_IDs[i])
  
  print(p)
}

```


```{r}
#looking at running imbalance of only injured players
Injured_Historical_Running <- Historical_Running_clean %>%
  filter(anon_id %in% injured_IDs)

#Making binary column if date was in time range of injury prognosis
Injured_Historical_Running$Date.in.Range <- rep(0, 1658)

#go through all of the injured players in the data set
for(i in 1:22){
  #get the dates each player was injured
  injury_dates <- unique(Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i],]$Date.of.Injury)
  
  #go through dates of injury for each player
  for(j in 1:length(injury_dates)){
    if(injured_IDs[i] == "ID_50"){ #ID_50 does not have enough running imbalance data
      break
    }
    #get the expected date of return for that instance of injury
    expected_return <- as.Date(Incident_Report_clean[Incident_Report_clean$anon_id==injured_IDs[i] & Incident_Report_clean$Date.of.Injury==injury_dates[j],]$Expected.End.Return[1])
    
    #if the date in running imbalance is between day of injury and last day of prediction, set as 1
    Injured_Historical_Running[Injured_Historical_Running$anon_id==injured_IDs[i] & Injured_Historical_Running$Date >= injury_dates[j] & Injured_Historical_Running$Date <= expected_return,]$Date.in.Range <- 1
  }
}

#making a column for the variance in running imbalance for each injury instance range
Injured_Historical_Running <- Injured_Historical_Running %>%
  filter(Date.in.Range == 1) %>%
  group_by(anon_id, Injury.Count) %>%
  mutate(Injury.Variability = var(Running.Imbalance)) %>%
  ungroup()

#adding injury and running data sets together
Injured_Data <- left_join(Injured_Historical_Running, Incident_Report_clean, by=c("anon_id", "Injury.Count"), relationship = "many-to-many") %>%
  #making new column if player returned in predicted time frame
  mutate(Return.in.Range = ifelse(Actual.Return>=Expected.Start.Return & Actual.Return <= Expected.End.Return, 1, 0)) %>%
  #removing rows that are missing important data
  filter(!is.na(Injury.Variability),
         !is.na(Return.in.Range))
```


### Logistic Regression Model
```{r}
set.seed(1000)
#making a 75% to 25% training to testing split
rows <- sample(1:nrow(Injured_Data), size=(nrow(Injured_Data)*0.75), replace=FALSE)
Injured_train <- Injured_Data[rows,]
Injured_test <- Injured_Data[-rows,]

#building logistic regression model from training data
return_to_play_model <- glm(Return.in.Range~Injury.Variability, data=Injured_train, family="binomial")

#looking at coefficients and p-values
summary(return_to_play_model)

#making predictions on testing data based off of the model built
Injured_test <- Injured_test %>%
  mutate(Prediction = ifelse(predict(return_to_play_model, newdata=Injured_test, type="response")>0.5, 1, 0))

#calculating CER
Injured_test %>%
  summarize(CER = mean(Prediction != Return.in.Range))

```


```{r Cross validating logistic regression model}
#making model with all of the data
return_to_play_cv <- glm(Return.in.Range~Injury.Variability, data=Injured_Data, family="binomial")

#making cost function for CER
cost <- function(obs, pred){
  mean((pred <= 0.5) & obs==1 | (pred > 0.5) & obs==0)
}

set.seed(1000)

#cross validating with K=10
ten_cv <- cv.glm(data=Injured_Data,glmfit=return_to_play_cv,cost,K=10)

#extract average error
ten_cv$delta[1]
```


### Bootstrapping Differences Between In and Out of Range Return to Plays
```{r Making separate data sets for bootstrapped comparison}
#taking only players who recovered in predicted time frame
In_Range <- Injured_Data %>%
  filter(Return.in.Range == 1,
         !is.na(Injury.Variability))

#taking only players who did not recover in the predicted time frame
Out_Range <- Injured_Data %>%
  filter(Return.in.Range == 0,
         !is.na(Injury.Variability))
```


```{r Boostrapping variances across both groups}
#making data frame to hold values
Range_Variances <- data.frame(in.avg.var = rep(NA, 5000),
                              out.avg.var = rep(NA, 5000),
                              diff.avg.var = rep(NA, 5000))

#bootstrapping 5000 times
for(i in 1:5000){
  set.seed(i)
  
  #sample from players who recovered in predicted range
  in_sample <- sample_n(In_Range, size=308, replace=TRUE)
  #sample fro players who did not recover in predicted range
  out_sample <- sample_n(Out_Range, size=477, replace=TRUE)
  
  
  #calculating variances of each sample and storing in data frame
  Range_Variances[i,1] <- mean(in_sample$Injury.Variability)
  Range_Variances[i,2] <- mean(out_sample$Injury.Variability)
  Range_Variances[i,3] <- Range_Variances[i,2] - Range_Variances[i,1] #diff in variances
}
```


```{r Plotting results from bootstrap}
#plotting differences in average variance
ggplot(data=Range_Variances, aes(diff.avg.var)) +
  geom_histogram() +
  #adding in 90% CI (does not include 0)
  geom_vline(xintercept = quantile(Range_Variances$diff.avg.var, 0.05), color ="#CFB87C") +
  geom_vline(xintercept = quantile(Range_Variances$diff.avg.var, 0.95), color ="#CFB87C")

#plotting average variances of difference groups
ggplot(data=Range_Variances) +
  #players who recovered in predicted time frame
  geom_histogram(aes(in.avg.var), alpha = 0.75) +
  #players who did not recover in the predicted time frame
  geom_histogram(aes(out.avg.var), alpha = 0.75, fill ="#CFB87C") +
  labs(x="Average Variance")
```


```{r Removing unnecessary objects created during this analysis}
remove(p,i,j,rows,ten_cv, cost, Injured_Data, Injured_Historical_Running, Injured_test, Injured_train, Range_Variances, return_to_play_cv, return_to_play_model, expected_return, injury_dates, In_Range, Out_Range, in_sample, out_sample)
```